{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"LawChatBot\\gcpservicekey.json\"\n",
    "PROJECT_ID = \"lawrag\"\n",
    "LOCATION = \"us-central1\"\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = VertexAIEmbeddings(model_name=\"text-embedding-005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.read_parquet(\"embeddings_gemini_text-005.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "  Moneys received or tendered in evidence in any United States Court, or before any officer thereof, which have been paid to or received by any official as a bribe, shall, after the final disposition\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "testing= sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_tokens=1024, overlap=128):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Same tokenizer as text-embedding-005\n",
    "    tokens = tokenizer.encode(text)\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        chunk = tokens[start:start + max_tokens]\n",
    "        chunks.append(tokenizer.decode(chunk))\n",
    "        start += max_tokens - overlap  # Sliding window\n",
    "    return chunks\n",
    "\n",
    "sample = chunk_text(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(texts, batch_size=32):\n",
    "    \"\"\"\n",
    "    Compute embeddings in batches using VertexAIEmbeddings in LangChain.\n",
    "    Args:\n",
    "        texts (list of str): List of text data to embed.\n",
    "        batch_size (int): Number of texts to process per batch.\n",
    "\n",
    "    Returns:\n",
    "        list: List of embedding vectors.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating Embeddings\"):\n",
    "        batch = texts[i:i + batch_size]  # Get batch of texts\n",
    "        batch_embeddings = embeddings_model.embed_documents(batch)  # Generate embeddings\n",
    "        embeddings.extend(batch_embeddings)  # Store results\n",
    "\n",
    "    return embeddings  # Returning list of lists (each embedding is a list of floats)\n",
    "\n",
    "# Store embeddings as a list of lists in DataFrame\n",
    "\n",
    "query_embedding = get_embeddings(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1663\n",
      "Most similar document index: 678\n"
     ]
    }
   ],
   "source": [
    "query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "\n",
    "\n",
    "# Convert the embeddings from a Pandas Series to a NumPy array\n",
    "embeddings = np.vstack(doc['Embedding'].values)  # Stack into a 2D array\n",
    "\n",
    "print(type(embeddings))  # Should print <class 'numpy.ndarray'>\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarities = cosine_similarity(query_embedding, embeddings)\n",
    "print(len(similarities[0]))\n",
    "\n",
    "# Get the index of the most similar document\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "print(\"Most similar document index:\", most_similar_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar document indices: [678 248 231 868 991]\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_embedding, embeddings)\n",
    "\n",
    "# Get the indices of the top 5 most similar documents (sorted in descending order)\n",
    "top_5_indices = np.argsort(similarities[0])[-5:][::-1]\n",
    "\n",
    "print(\"Top 5 most similar document indices:\", top_5_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(top_5_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moneys received or tendered in evidence in any United States Court, or before any officer thereof, which have been paid to or received by any official as a bribe, shall, after the final disposition of the case, proceeding or investigation, be deposited in the registry of the court to be disposed of in accordance with the order of the court, to be subject, however, to the provisions of section 2042 of Title 28.\\n(June 25, 1948, ch. 645, 62 Stat. 840; May 24, 1949, ch. 139, §55, 63 Stat. 96; renumbered §3666, Pub. L. 98–473, title II, §212(a)(1), Oct. 12, 1984, 98 Stat. 1987.)\\n\\nHistorical and Revision Notes\\n1948 Act\\nBased on title 18, U.S.C., 1940 ed., §570 (Jan. 7, 1925, ch. 33, 43 Stat. 726).\\nChanges were made in phraseology.\\n\\n1949 Act\\nThis section [section 55] corrects section 3612 of title 18, U.S.C., so that the reference in such section will be to the correct section number in title 28, U.S.C., as revised and enacted in 1948.\\n\\nEditorial Notes\\nAmendments\\n1949—Act May 24, 1949, substituted \"section 2042\" for \"section 852\".\\n'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc['Processed_Content'][678]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  Training Requirement.—\\n\\n(1) In general.—In order for an officer or employee of the Bureau of Prisons, including a correctional officer, to be eligible to receive and carry oleoresin capsicum spray pursuant to this section, the officer or employee\\n  \\n'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH FOUND\n",
      "MATCH FOUND\n",
      "MATCH FOUND\n",
      "MATCH FOUND\n",
      "MATCH FOUND\n"
     ]
    }
   ],
   "source": [
    "for x in top_5_indices.tolist():\n",
    "    if str(sample[0]) in str(doc['Processed_Content'][x]):\n",
    "        print(\"MATCH FOUND\")\n",
    "    else:\n",
    "        print(\"No match found\")\n",
    "#doc['Processed_Content'][most_similar_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athlyze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
