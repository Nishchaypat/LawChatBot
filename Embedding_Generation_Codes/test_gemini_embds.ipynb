{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"..\\gcpservicekey.json\"\n",
    "PROJECT_ID = \"lawrag\"\n",
    "LOCATION = \"us-central1\"\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = VertexAIEmbeddings(model_name=\"text-embedding-005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.read_parquet(r\"..\\New_Embeddings_2025\\embeddings_gemini_text-005.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "  will be placed in the Child Pornography Victims Reserve, which was created in accordance with section 1402.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "testing= sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_tokens=1024, overlap=128):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Same tokenizer as text-embedding-005\n",
    "    tokens = tokenizer.encode(text)\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        chunk = tokens[start:start + max_tokens]\n",
    "        chunks.append(tokenizer.decode(chunk))\n",
    "        start += max_tokens - overlap  # Sliding window\n",
    "    return chunks\n",
    "\n",
    "sample = chunk_text(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(texts, batch_size=32):\n",
    "    \"\"\"\n",
    "    Compute embeddings in batches using VertexAIEmbeddings in LangChain.\n",
    "    Args:\n",
    "        texts (list of str): List of text data to embed.\n",
    "        batch_size (int): Number of texts to process per batch.\n",
    "\n",
    "    Returns:\n",
    "        list: List of embedding vectors.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating Embeddings\"):\n",
    "        batch = texts[i:i + batch_size]  # Get batch of texts\n",
    "        batch_embeddings = embeddings_model.embed_documents(batch)  # Generate embeddings\n",
    "        embeddings.extend(batch_embeddings)  # Store results\n",
    "\n",
    "    return embeddings  # Returning list of lists (each embedding is a list of floats)\n",
    "\n",
    "# Store embeddings as a list of lists in DataFrame\n",
    "\n",
    "query_embedding = get_embeddings(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1663\n",
      "Most similar document index: 96\n"
     ]
    }
   ],
   "source": [
    "query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "\n",
    "\n",
    "# Convert the embeddings from a Pandas Series to a NumPy array\n",
    "embeddings = np.vstack(doc['Embedding'].values)  # Stack into a 2D array\n",
    "\n",
    "print(type(embeddings))  # Should print <class 'numpy.ndarray'>\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarities = cosine_similarity(query_embedding, embeddings)\n",
    "print(len(similarities[0]))\n",
    "\n",
    "# Get the index of the most similar document\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "print(\"Most similar document index:\", most_similar_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar document indices: [96 94 79 75 98]\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_embedding, embeddings)\n",
    "\n",
    "# Get the indices of the top 5 most similar documents (sorted in descending order)\n",
    "top_5_indices = np.argsort(similarities[0])[-5:][::-1]\n",
    "\n",
    "print(\"Top 5 most similar document indices:\", top_5_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(top_5_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(a) Deposits Into the Reserve.-Notwithstanding any other provision of law, there shall be deposited into the Child Pornography Victims Reserve established under section 1402(d)(6) of the Victims of Crime Act of 1984 (34 U.S.C. 20101(d)) all assessments collected under section 2259A and any gifts, bequests, or donations to the Child Pornography Victims Reserve from private entities or individuals.\\n\\n(b) Availability for Defined Monetary Assistance.-Amounts in the Child Pornography Victims Reserve shall be available for payment of defined monetary assistance pursuant to section 2259(d). If at any time the Child Pornography Victims Reserve has insufficient funds to make all of the payments ordered under section 2259(d), the Child Pornography Victims Reserve shall make such payments as it can satisfy in full from available funds. In determining the order in which such payments shall be made, the Child Pornography Victims Reserve shall make payments based on the date they were ordered, with the earliest-ordered payments made first.\\n\\n(c) Administration.-The Attorney General shall administer the Child Pornography Victims Reserve and shall issue guidelines and regulations to implement this section.\\n\\n(d) Sense of Congress.-It is the sense of Congress that individuals who violate this chapter prior to the date of the enactment of the Amy, Vicky, and Andy Child Pornography Victim Assistance Act of 2018, but who are sentenced after such date, shall be subject to the statutory scheme that was in effect at the time the offenses were committed.\\n\\n(Added Pub. L. 115–299, §5(c), Dec. 7, 2018, 132 Stat. 4387.)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc['Processed_Content'][96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  Training Requirement.—\\n\\n(1) In general.—In order for an officer or employee of the Bureau of Prisons, including a correctional officer, to be eligible to receive and carry oleoresin capsicum spray pursuant to this section, the officer or employee\\n  \\n'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH FOUND\n",
      "MATCH FOUND\n",
      "MATCH FOUND\n",
      "MATCH FOUND\n",
      "MATCH FOUND\n"
     ]
    }
   ],
   "source": [
    "for x in top_5_indices.tolist():\n",
    "    if str(sample[0]) in str(doc['Processed_Content'][x]):\n",
    "        print(\"MATCH FOUND\")\n",
    "    else:\n",
    "        print(\"No match found\")\n",
    "#doc['Processed_Content'][most_similar_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
