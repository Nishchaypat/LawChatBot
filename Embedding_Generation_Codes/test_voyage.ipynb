{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer\n",
    "import voyageai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "voyageai.api_key = os.getenv(\"VOYAGE_API\")\n",
    "vo = voyageai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('voyageai/voyage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.read_parquet(\"/Users/npatel237/LawChatBot/New_Embeddings_2025/embeddings_voyage.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "After the final decision, funds that have been given to or received by an official as a bribe and are received or submitted as evidence in any US court or before any of its officers shall\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_tokens=4096, overlap=512):\n",
    "    \"\"\"\n",
    "    Splits text into chunks based on the token limit of voyage-law-2 tokenizer.\n",
    "    Uses a sliding window approach with overlap.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to be chunked.\n",
    "        max_tokens (int): Maximum tokens per chunk (4096 for voyage-law-2).\n",
    "        overlap (int): Overlapping tokens to maintain context between chunks.\n",
    "\n",
    "    Returns:\n",
    "        list of str: List of text chunks.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        chunk = tokens[start:start + max_tokens]\n",
    "        chunks.append(tokenizer.decode(chunk))\n",
    "        start += max_tokens - overlap\n",
    "\n",
    "    return chunks\n",
    "\n",
    "sample = chunk_text(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model=\"voyage-law-2\", batch_size=32):\n",
    "    \"\"\"\n",
    "    Compute embeddings using the VoyageAI Python client in batches.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): List of text data to embed.\n",
    "        model (str): The embedding model to use.\n",
    "        batch_size (int): Number of texts per batch.\n",
    "\n",
    "    Returns:\n",
    "        list: List of embedding vectors.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    texts = [str(text) for text in texts]  \n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size] \n",
    "        \n",
    "        try:\n",
    "            response = vo.embed(batch, model=model)\n",
    "            batch_embeddings = response.embeddings  \n",
    "            embeddings.extend(batch_embeddings)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i // batch_size + 1}: {e}\")\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "query_embedding = get_embeddings(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1647\n",
      "Most similar document index: 670\n"
     ]
    }
   ],
   "source": [
    "query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "\n",
    "\n",
    "# Convert the embeddings from a Pandas Series to a NumPy array\n",
    "embeddings = np.vstack(doc['Embedding'].values)  # Stack into a 2D array\n",
    "\n",
    "print(type(embeddings))  # Should print <class 'numpy.ndarray'>\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarities = cosine_similarity(query_embedding, embeddings)\n",
    "print(len(similarities[0]))\n",
    "\n",
    "# Get the index of the most similar document\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "print(\"Most similar document index:\", most_similar_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\\'Moneys received or tendered in evidence in any United States Court, or before any officer thereof, which have been paid to or received by any official as a bribe, shall, after the final disposition of the case, proceeding or investigation, be deposited in the registry of the court to be disposed of in accordance with the order of the court, to be subject, however, to the provisions of section 2042 of Title 28.\\\\n(June 25, 1948, ch. 645, 62 Stat. 840; May 24, 1949, ch. 139, §55, 63 Stat. 96; renumbered §3666, Pub. L. 98–473, title II, §212(a)(1), Oct. 12, 1984, 98 Stat. 1987.)\\\\n\\\\nHistorical and Revision Notes\\\\n1948 Act\\\\nBased on title 18, U.S.C., 1940 ed., §570 (Jan. 7, 1925, ch. 33, 43 Stat. 726).\\\\nChanges were made in phraseology.\\\\n\\\\n1949 Act\\\\nThis section [section 55] corrects section 3612 of title 18, U.S.C., so that the reference in such section will be to the correct section number in title 28, U.S.C., as revised and enacted in 1948.\\\\n\\\\nEditorial Notes\\\\nAmendments\\\\n1949—Act May 24, 1949, substituted \"section 2042\" for \"section 852\".\\\\n\\']]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc['Processed_Content'][670]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athlyze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
