{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/npatel237/LawChatBot/gcpservicekey.json\"\n",
    "PROJECT_ID = \"lawrag\"\n",
    "LOCATION = \"us-central1\"\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = VertexAIEmbeddings(model_name=\"text-embedding-005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_tokens=4096, overlap=512):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Same tokenizer as text-embedding-005\n",
    "    tokens = tokenizer.encode(text)\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        chunk = tokens[start:start + max_tokens]\n",
    "        chunks.append(tokenizer.decode(chunk))\n",
    "        start += max_tokens - overlap  # Sliding window\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, batch_size=32):\n",
    "    \"\"\"\n",
    "    Compute embeddings in batches using VertexAIEmbeddings in LangChain.\n",
    "    Args:\n",
    "        texts (list of str): List of text data to embed.\n",
    "        batch_size (int): Number of texts to process per batch.\n",
    "\n",
    "    Returns:\n",
    "        list: List of embedding vectors.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating Embeddings\"):\n",
    "        batch = texts[i:i + batch_size]  # Get batch of texts\n",
    "        batch_embeddings = embeddings_model.embed_documents(batch)  # Generate embeddings\n",
    "        embeddings.extend(batch_embeddings)  # Store results\n",
    "\n",
    "    return embeddings  # Returning list of lists (each embedding is a list of floats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Embedding per section:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.read_csv('/Users/npatel237/LawChatBot/Processed_CSV_Data/Title18_processed_sections.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum text length in Processed_Content column: 39390\n",
      "Total Rows: 1647\n"
     ]
    }
   ],
   "source": [
    "processed_content = doc['Processed_Content']\n",
    "max_length = doc['Processed_Content'].apply(len).max()\n",
    "print(\"Maximum text length in Processed_Content column:\", max_length)\n",
    "print(\"Total Rows:\", len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc[\"Processed_Content\"] = doc[\"Processed_Content\"].apply(lambda x: chunk_text(x) if len(x) > 4096 else [x])\n",
    "df_exploded = doc.explode(\"Processed_Content\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 52/52 [00:23<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "df_exploded[\"Embedding\"] = get_embeddings(df_exploded[\"Processed_Content\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1647"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_exploded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded.to_parquet(\"embeddings_gemini_text-005.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Embedding per Chapter and Pages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6001\\nImmunity of Witnesses\\nV.\\n5001\\nCorrect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37\\n756, 3058\\n38\\nT. 22 §465\\n39\\n5, 3241\\n51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79\\n1003\\n80\\n287, 1001\\n81\\n289\\n82\\n641, 136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123\\n912\\n124\\n211\\n125\\n543\\n126\\n541\\n127\\n1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199\\n205\\n200\\n204\\n201\\n1913\\n202\\n216\\n203\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk\n",
       "0  6001\\nImmunity of Witnesses\\nV.\\n5001\\nCorrect...\n",
       "1  37\\n756, 3058\\n38\\nT. 22 §465\\n39\\n5, 3241\\n51...\n",
       "2  79\\n1003\\n80\\n287, 1001\\n81\\n289\\n82\\n641, 136...\n",
       "3  123\\n912\\n124\\n211\\n125\\n543\\n126\\n541\\n127\\n1...\n",
       "4  199\\n205\\n200\\n204\\n201\\n1913\\n202\\n216\\n203\\n..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pd.read_csv('../Title18_CSV_Data/chunked_title_18semchunk_pages.csv', encoding='utf-8')\n",
    "doc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc['chunk'] = doc['chunk'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 68/68 [00:23<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "df_exploded = doc.explode(\"chunk\").reset_index(drop=True)\n",
    "df_exploded[\"Embedding\"] = get_embeddings(df_exploded[\"chunk\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded.to_parquet(\"embeddings_gemini_text-005_pages.parquet\", engine=\"pyarrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athlyze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
