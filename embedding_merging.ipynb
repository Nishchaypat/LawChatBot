{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pyarrow.parquet as pq\n",
    "import spacy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Load NLP pipeline for query analysis\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Legal dictionary terms - expand as needed\n",
    "LEGAL_TERMS = {\n",
    "    \"habeas corpus\", \"mens rea\", \"actus reus\", \"stare decisis\", \n",
    "    \"prima facie\", \"de novo\", \"res judicata\", \"certiorari\",\n",
    "    \"statutory\", \"U.S.C.\", \"CFR\", \"jurisdiction\", \"adjudicate\"\n",
    "}\n",
    "\n",
    "# Regex patterns for legal citations\n",
    "CITATION_PATTERNS = [\n",
    "    r'\\d+\\s+U\\.S\\.C\\.\\s+§*\\s*\\d+',  # US Code\n",
    "    r'\\d+\\s+C\\.F\\.R\\.\\s+§*\\s*\\d+',   # Code of Federal Regulations\n",
    "    r'[A-Za-z]+\\s+v\\.\\s+[A-Za-z]+',  # Case names\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Embeddings from Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalEmbeddingLoader:\n",
    "    \"\"\"Loads embeddings from parquet files for both models and all granularity levels.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = base_path\n",
    "        self.gemini_embeddings = {}\n",
    "        self.voyager_embeddings = {}\n",
    "        self.metadata = {}\n",
    "        \n",
    "    def load_embeddings(self):\n",
    "        \"\"\"Load the six specified embedding files.\"\"\"\n",
    "        file_mappings = {\n",
    "            \"gemini_chapters\": \"embeddings_gemini_text-005_chapters_semchunk.parquet\",\n",
    "            \"voyager_chapters\": \"embeddings_voyage_per_chapter_semchunked.parquet\",\n",
    "            \"gemini_pages\": \"embeddings_gemini_text-005_pages_semchunk.parquet\",\n",
    "            \"voyager_pages\": \"embeddings_voyage_per_pages_semchunked.parquet\",\n",
    "            \"gemini_sections\": \"embeddings_gemini_text-005.parquet\",\n",
    "            \"voyager_sections\": \"embeddings_voyage.parquet\",\n",
    "        }\n",
    "\n",
    "        for key, file_name in file_mappings.items():\n",
    "            print(self.base_path)\n",
    "            file_path = os.path.join(self.base_path, key.split(\"_\")[-1], file_name)\n",
    "            print(file_path)\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"File {file_name} not found. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Read parquet file\n",
    "            table = pq.read_table(file_path)\n",
    "            df = table.to_pandas()\n",
    "            print(f\"\\nColumns in {file_name}: {df.columns.tolist()}\")\n",
    "            # Extract embeddings and metadata\n",
    "            embeddings = np.stack(df[\"Embedding\"].values)\n",
    "\n",
    "            # Determine model and granularity\n",
    "            model, granularity = key.split(\"_\")\n",
    "\n",
    "            # Store embeddings\n",
    "            if model == \"gemini\":\n",
    "                self.gemini_embeddings[granularity] = torch.tensor(embeddings, dtype=torch.float32)\n",
    "            else:\n",
    "                self.voyager_embeddings[granularity] = torch.tensor(embeddings, dtype=torch.float32)\n",
    "\n",
    "            # Store metadata\n",
    "            self.metadata[key] = df.drop('Embedding', axis=1)\n",
    "\n",
    "            print(f\"Loaded {file_name} ({model} - {granularity})\")\n",
    "        return self.gemini_embeddings, self.voyager_embeddings, self.metadata\n",
    "\n",
    "    def get_embedding_dimensions(self):\n",
    "        \"\"\"Return the dimensions of embeddings for both models.\"\"\"\n",
    "        gemini_dim = {k: v.shape[1] for k, v in self.gemini_embeddings.items()}\n",
    "        voyager_dim = {k: v.shape[1] for k, v in self.voyager_embeddings.items()}\n",
    "        return gemini_dim, voyager_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming LegalEmbeddingLoader class has been defined as in the code you provided\n",
    "# loader = LegalEmbeddingLoader(base_path=\"New_Embeddings_2025\")\n",
    "# gemini_embeddings, voyager_embeddings, metadata = loader.load_embeddings()\n",
    "\n",
    "# # Get the embedding dimensions\n",
    "# gemini_dim, voyager_dim = loader.get_embedding_dimensions()\n",
    "\n",
    "# # Print the dimensions for both models\n",
    "# print(\"Gemini Embedding Dimensions:\")\n",
    "# print(gemini_dim)\n",
    "\n",
    "# print(\"\\nVoyager Embedding Dimensions:\")\n",
    "# print(voyager_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Analysis and Intent Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalQueryAnalyzer:\n",
    "    \"\"\"Analyzes legal queries to determine intent and model weights.\"\"\"\n",
    "    \n",
    "    def __init__(self, legal_terms=LEGAL_TERMS, citation_patterns=CITATION_PATTERNS, model_name='bert-base-uncased'):\n",
    "        self.legal_terms = legal_terms\n",
    "        self.citation_patterns = citation_patterns\n",
    "        self.model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name)\n",
    "        \n",
    "    def analyze_query(self, query):\n",
    "        \"\"\"\n",
    "        Analyze query characteristics to determine model weights.\n",
    "        Returns a dictionary of features and recommended weights.\n",
    "        \"\"\"\n",
    "        # Process with spaCy\n",
    "        doc = nlp(query)\n",
    "        \n",
    "        # Feature extraction\n",
    "        features = {\n",
    "            'legal_term_density': self._calculate_legal_term_density(query),\n",
    "            'citation_count': self._count_citations(query),\n",
    "            'structural_complexity': self._assess_complexity(doc),\n",
    "            'query_length': len(doc),\n",
    "            'jurisdiction_signals': self._detect_jurisdiction(doc)\n",
    "        }\n",
    "        \n",
    "        # Calculate recommended weights\n",
    "        weights = self._determine_weights(features)\n",
    "        \n",
    "        return {\n",
    "            'features': features,\n",
    "            'weights': weights,\n",
    "            'query_embedding': self._get_query_embedding(query)\n",
    "        }\n",
    "    \n",
    "    def _calculate_legal_term_density(self, query):\n",
    "        \"\"\"Calculate the density of legal terminology in the query.\"\"\"\n",
    "        # Normalize and tokenize query\n",
    "        query_lower = query.lower()\n",
    "        total_tokens = len(query_lower.split())\n",
    "        \n",
    "        # Count legal terms\n",
    "        legal_term_count = sum(1 for term in self.legal_terms if term.lower() in query_lower)\n",
    "        \n",
    "        # Calculate density\n",
    "        if total_tokens > 0:\n",
    "            return (legal_term_count / total_tokens) * 100\n",
    "        return 0\n",
    "    \n",
    "    def _count_citations(self, query):\n",
    "        \"\"\"Count legal citations in the query.\"\"\"\n",
    "        citation_count = 0\n",
    "        for pattern in self.citation_patterns:\n",
    "            citation_count += len(re.findall(pattern, query))\n",
    "        return citation_count\n",
    "    \n",
    "    def _assess_complexity(self, doc):\n",
    "        \"\"\"\n",
    "        Assess the structural complexity of the query.\n",
    "        Returns a score from 0-1 based on:\n",
    "        - Number of clauses\n",
    "        - Presence of legal conditionals\n",
    "        - Sentence structure complexity\n",
    "        \"\"\"\n",
    "        # Count clauses\n",
    "        clause_markers = [\"if\", \"when\", \"whether\", \"notwithstanding\", \"provided that\"]\n",
    "        clause_count = sum(1 for token in doc if token.text.lower() in clause_markers)\n",
    "        \n",
    "        # Check for complex legal conditionals\n",
    "        has_conditionals = any(cm in doc.text.lower() for cm in clause_markers)\n",
    "        \n",
    "        # Assess syntactic complexity (simplified)\n",
    "        depth = max((token.dep_.count('_') for token in doc), default=0)\n",
    "        \n",
    "        # Calculate complexity score (0-1)\n",
    "        complexity = min(1.0, (clause_count * 0.2) + (0.3 if has_conditionals else 0) + (depth * 0.1))\n",
    "        \n",
    "        return complexity\n",
    "    \n",
    "    def _detect_jurisdiction(self, doc):\n",
    "        \"\"\"\n",
    "        Detect jurisdictional signals in the query.\n",
    "        Returns a dictionary of jurisdictional features.\n",
    "        \"\"\"\n",
    "        # Look for jurisdictional entities\n",
    "        jurisdictions = {\n",
    "            'federal': 0,\n",
    "            'state': 0,\n",
    "            'international': 0,\n",
    "            'specific_court': None\n",
    "        }\n",
    "        \n",
    "        # Check for federal signals\n",
    "        federal_terms = [\"federal\", \"U.S.\", \"United States\", \"SCOTUS\", \"Supreme Court\"]\n",
    "        jurisdictions['federal'] = any(term.lower() in doc.text.lower() for term in federal_terms)\n",
    "        \n",
    "        # Check for state signals\n",
    "        state_names = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \n",
    "    \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \n",
    "    \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \n",
    "    \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \n",
    "    \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \n",
    "    \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \n",
    "    \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "  # Add all states\n",
    "        jurisdictions['state'] = any(state in doc.text for state in state_names)\n",
    "        \n",
    "        # Check for international signals\n",
    "        international_terms = [\"international\", \"foreign\", \"treaty\", \"convention\"]\n",
    "        jurisdictions['international'] = any(term.lower() in doc.text.lower() for term in international_terms)\n",
    "        \n",
    "        # Look for specific courts\n",
    "        court_patterns = [\"Circuit\", \"District Court\", \"Supreme Court\"]\n",
    "        for pattern in court_patterns:\n",
    "            if pattern in doc.text:\n",
    "                jurisdictions['specific_court'] = pattern\n",
    "                break\n",
    "                \n",
    "        return jurisdictions\n",
    "    \n",
    "    def _determine_weights(self, features):\n",
    "        \"\"\"\n",
    "        Determine the optimal weights for each model based on features.\n",
    "        Uses a rule-based approach initially, could be replaced with ML model.\n",
    "        \"\"\"\n",
    "        # Default weights slightly favor specialized model\n",
    "        gemini_weight = 0.4\n",
    "        voyager_weight = 0.6\n",
    "        \n",
    "        # Adjust for legal density and citations\n",
    "        if features['legal_term_density'] > 5 or features['citation_count'] > 0:\n",
    "            # Increase weight for legal model\n",
    "            voyager_weight += 0.15\n",
    "            gemini_weight -= 0.15\n",
    "        \n",
    "        # Adjust for complexity\n",
    "        if features['structural_complexity'] > 0.7:\n",
    "            voyager_weight += 0.1\n",
    "            gemini_weight -= 0.1\n",
    "        \n",
    "        # Adjust for jurisdictional specificity\n",
    "        if features['jurisdiction_signals']['specific_court']:\n",
    "            voyager_weight += 0.1\n",
    "            gemini_weight -= 0.1\n",
    "        \n",
    "        # Ensure weights are valid\n",
    "        voyager_weight = min(max(voyager_weight, 0.1), 0.9)\n",
    "        gemini_weight = 1.0 - voyager_weight\n",
    "        \n",
    "        return {\n",
    "            'gemini': gemini_weight,\n",
    "            'voyager': voyager_weight\n",
    "        }\n",
    "    \n",
    "    def _get_query_embedding(self, query):\n",
    "        \"\"\"Generate embedding for the query using the pretrained model.\"\"\"\n",
    "        inputs = self.tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention-Based Fusion Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLevelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced attention mechanism with dimension fixes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_dim=768):\n",
    "        super(MultiLevelAttention, self).__init__()\n",
    "        \n",
    "        # Model dimensions\n",
    "        self.gemini_dim = 768\n",
    "        self.voyager_dim = 1024\n",
    "        self.output_dim = output_dim\n",
    "        self.granularities = ['sections', 'chapters', 'pages']\n",
    "        self.cross_attention_weights = {}\n",
    "        # Query projection\n",
    "        self.query_projector = nn.Linear(768, output_dim)\n",
    "        \n",
    "        # Document projectors\n",
    "        self.gemini_projector = nn.Linear(self.gemini_dim, output_dim)\n",
    "        self.voyager_projector = nn.Linear(self.voyager_dim, output_dim)\n",
    "        \n",
    "        # Aggregation\n",
    "        self.aggregation_layer = nn.Linear(output_dim, output_dim)\n",
    "        self.layer_norm = nn.LayerNorm(output_dim)\n",
    "\n",
    "    def forward(self, gemini_embeddings, voyager_embeddings, query_embedding, weights):\n",
    "        # Project query\n",
    "        query_projected = self.query_projector(query_embedding)\n",
    "        \n",
    "        granularity_results = {}\n",
    "        diagnostics = {}\n",
    "        \n",
    "        for granularity in self.granularities:\n",
    "            print(f\"Processing granularity: {granularity}\")\n",
    "            gemini_emb = gemini_embeddings[granularity]\n",
    "            voyager_emb = voyager_embeddings[granularity]\n",
    "            \n",
    "            # Project document embeddings\n",
    "            gemini_proj = self.gemini_projector(gemini_emb)\n",
    "            voyager_proj = self.voyager_projector(voyager_emb)\n",
    "            \n",
    "\n",
    "            gemini_proj = gemini_proj[:, :self.output_dim]  # Ensure [num_docs, 768]\n",
    "            voyager_proj = voyager_proj[:, :self.output_dim]\n",
    "            # Calculate similarities (fixed dimensions)\n",
    "            gemini_similarity = F.cosine_similarity(\n",
    "                gemini_proj,\n",
    "                query_projected.unsqueeze(0),\n",
    "                dim=1\n",
    "            ).unsqueeze(0)  # Add batch dimension for softmax\n",
    "            \n",
    "            voyager_similarity = F.cosine_similarity(\n",
    "                voyager_proj,\n",
    "                query_projected.unsqueeze(0),\n",
    "                dim=1\n",
    "            ).unsqueeze(0)\n",
    "            \n",
    "            # Normalize similarities\n",
    "            gemini_weights = F.softmax(gemini_similarity, dim=-1)\n",
    "            voyager_weights = F.softmax(voyager_similarity, dim=-1)\n",
    "            print(f\"Gemini weights shape: {gemini_weights.shape}\")\n",
    "            print(f\"Gemini proj shape: {gemini_proj.shape}\")\n",
    "            # Weighted sum with proper dimensions\n",
    "            gemini_weighted = torch.matmul(\n",
    "                gemini_weights,\n",
    "                gemini_proj.T\n",
    "            ).squeeze(0)  # Remove batch dimension\n",
    "            \n",
    "            voyager_weighted = torch.matmul(\n",
    "                voyager_weights,\n",
    "                voyager_proj.T\n",
    "            ).squeeze(0)\n",
    "            \n",
    "            # Combine model embeddings\n",
    "            new_size = (weights['gemini'] * gemini_weighted).shape[-1] - (weights['voyager'] * voyager_weighted).shape[-1]  # Padding size for smaller model\n",
    "            print(f\"New size: {new_size}\")\n",
    "            granularity_combined = (\n",
    "                weights['gemini'] * gemini_weighted +\n",
    "                F.pad(weights['voyager'] * voyager_weighted, (0, new_size), \"constant\", 0)\n",
    "                \n",
    "            )\n",
    "            \n",
    "            granularity_results[granularity] = granularity_combined\n",
    "            print(f\"Granularity Completed: {granularity}\")\n",
    "        # Aggregate results\n",
    "        # Unified dimension handling\n",
    "        max_dim = max(granularity_results[gran].shape[-1] for gran in self.granularities)\n",
    "\n",
    "        combined_embedding = torch.stack([\n",
    "            F.pad(gran_res, (0, max_dim - gran_res.shape[-1])) \n",
    "            for gran_res in granularity_results.values()\n",
    "        ], dim=0).mean(dim=0)\n",
    "\n",
    "        # combined_embedding = torch.stack([\n",
    "        #             granularity_results[gran] for gran in self.granularities\n",
    "        #         ], dim=0).mean(dim=0)\n",
    "        self.cross_attention_weights = {\n",
    "            'gemini': gemini_weights.detach().cpu(),\n",
    "            'voyager': voyager_weights.detach().cpu(),\n",
    "            'combined': granularity_combined.detach().cpu()\n",
    "        }\n",
    "\n",
    "        # Final processing\n",
    "        # Modified final processing with dimension enforcement\n",
    "        fused_embedding = self.layer_norm(\n",
    "            self.aggregation_layer(\n",
    "                nn.Linear(2176, 768)(combined_embedding)  # Project to correct dimension\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return fused_embedding, {\n",
    "            'processed_embeddings': granularity_results,\n",
    "            'diagnostics': diagnostics,\n",
    "            'cross_attention_weights': self.cross_attention_weights \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Legal RAG System Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalAttentionRAG:\n",
    "    \"\"\"\n",
    "    Complete Legal RAG system using attention-based fusion of embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_path, query_embedding_dim=768, \n",
    "                 device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        print(f\"Initializing LegalAttentionRAG on device: {device}\")\n",
    "        \n",
    "        # Initialize embedding loader\n",
    "        self.embedding_loader = LegalEmbeddingLoader(embedding_path)\n",
    "        self.gemini_embeddings, self.voyager_embeddings, self.metadata = self.embedding_loader.load_embeddings()\n",
    "        # Add to __init__\n",
    "        self.gemini_projector = nn.Linear(768, 768)  # Maintain original dimension\n",
    "        self.voyager_projector = nn.Linear(1024, 768)  # Project to match Gemini\n",
    "\n",
    "        # Get embedding dimensions and verify\n",
    "        gemini_dims, voyager_dims = self.embedding_loader.get_embedding_dimensions()\n",
    "        print(f\"Gemini Embedding Dimensions:\\n{gemini_dims}\")\n",
    "        print(f\"Voyager Embedding Dimensions:\\n{voyager_dims}\")\n",
    "        \n",
    "        # Initialize query analyzer\n",
    "        self.query_analyzer = LegalQueryAnalyzer()\n",
    "        \n",
    "        # Initialize attention fusion model - using fixed version that doesn't rely on dimension dicts\n",
    "        self.attention_model = MultiLevelAttention(output_dim=query_embedding_dim).to(device)\n",
    "        \n",
    "        # Move embeddings to device\n",
    "        for key in self.gemini_embeddings:\n",
    "            self.gemini_embeddings[key] = self.gemini_embeddings[key].to(device)\n",
    "            self.voyager_embeddings[key] = self.voyager_embeddings[key].to(device)\n",
    "            \n",
    "        print(\"LegalAttentionRAG system initialized successfully\")\n",
    "\n",
    "            \n",
    "    def process_query(self, query, top_k=5):\n",
    "        \"\"\"Process a legal query using the simplified attention fusion.\"\"\"\n",
    "        # 1. Analyze query to determine intent and weights\n",
    "        query_analysis = self.query_analyzer.analyze_query(query)\n",
    "        weights = query_analysis['weights']\n",
    "        features = query_analysis['features']\n",
    "        query_embedding = query_analysis['query_embedding'].to(self.device)\n",
    "        \n",
    "        print(f\"Query embedding shape: {query_embedding.shape}\")\n",
    "        print(f\"Model weights: Gemini={weights['gemini']:.2f}, Voyager={weights['voyager']:.2f}\")\n",
    "        \n",
    "        # 2. Apply attention-based fusion\n",
    "        try:\n",
    "            fused_embedding, attention_info = self.attention_model(\n",
    "                self.gemini_embeddings,\n",
    "                self.voyager_embeddings,\n",
    "                query_embedding,\n",
    "                weights\n",
    "            )\n",
    "            \n",
    "            # Log dimensions for debugging\n",
    "            if 'diagnostics' in attention_info:\n",
    "                print(\"Embedding shapes:\")\n",
    "                for key, value in attention_info['diagnostics'].items():\n",
    "                    print(f\"  {key}: {value}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in attention model: {e}\")\n",
    "            # Log shapes to help diagnose the issue\n",
    "            print(f\"Query shape: {query_embedding.shape}\")\n",
    "            for granularity in self.gemini_embeddings.keys():\n",
    "                print(f\"Gemini {granularity}: {self.gemini_embeddings[granularity].shape}\")\n",
    "                print(f\"Voyager {granularity}: {self.voyager_embeddings[granularity].shape}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "        \n",
    "        # 3. Retrieve most relevant documents using the fused embedding\n",
    "        results = {}\n",
    "        # Modified similarity calculation with dimension alignment\n",
    "        for granularity in ['sections', 'chapters', 'pages']:\n",
    "            gemini_emb = self.gemini_projector(self.gemini_embeddings[granularity])  # [n_docs, 768]\n",
    "            voyager_emb = self.voyager_projector(self.voyager_embeddings[granularity])  # [n_docs, 768]\n",
    "            \n",
    "            # Calculate similarity scores with proper dimension alignment\n",
    "            gemini_scores = F.cosine_similarity(\n",
    "                fused_embedding.unsqueeze(0).unsqueeze(1),  # [1, 1, 768]\n",
    "                gemini_emb.unsqueeze(0).unsqueeze(0),       # [1, 1, n_docs, 768]\n",
    "                dim=3\n",
    "            ).squeeze()\n",
    "            \n",
    "            voyager_scores = F.cosine_similarity(\n",
    "                fused_embedding.unsqueeze(0).unsqueeze(1),  # [1, 1, 768]\n",
    "                voyager_emb.unsqueeze(0).unsqueeze(0),      # [1, 1, n_docs, 768]\n",
    "                dim=3\n",
    "            ).squeeze()\n",
    "    \n",
    "    # Rest of your code remains the same\n",
    "\n",
    "            \n",
    "            # Weighted combination of scores\n",
    "            new_size = (weights['gemini'] * gemini_scores).shape[-1] - (weights['voyager'] * voyager_scores).shape[-1]  # Padding size for smaller model\n",
    "            print(f\"New size: {new_size}\")\n",
    "            combined_scores = (\n",
    "                weights['gemini'] * gemini_scores + \n",
    "                F.pad(weights['voyager'] * voyager_scores, (0, new_size), \"constant\", 0)\n",
    "            )\n",
    "            \n",
    "            # Get top-k results\n",
    "            top_indices = combined_scores.argsort(descending=True)[:top_k]\n",
    "            \n",
    "            # Retrieve metadata for these indices\n",
    "            gemini_meta = self.metadata[f\"gemini_{granularity}\"].iloc[top_indices.cpu().numpy()]\n",
    "            voyager_meta = self.metadata[f\"voyager_{granularity}\"].iloc[top_indices.cpu().numpy()]\n",
    "            \n",
    "            # Store results\n",
    "            results[granularity] = {\n",
    "                'indices': top_indices.cpu().detach().numpy(),\n",
    "                'scores': combined_scores[top_indices].cpu().detach().numpy(),\n",
    "                'gemini_metadata': gemini_meta,\n",
    "                'voyager_metadata': voyager_meta\n",
    "            }\n",
    "        # 4. Return results with diagnostic information\n",
    "        return {\n",
    "            'query_analysis': {\n",
    "                'features': features,\n",
    "                'weights': weights\n",
    "            },\n",
    "            'attention_weights': attention_info.get('cross_attention_weights'),\n",
    "            'results': results\n",
    "        }\n",
    "    \n",
    "    def explain_weights(self, query):\n",
    "        \"\"\"Generate an explanation of why particular weights were chosen.\"\"\"\n",
    "        analysis = self.query_analyzer.analyze_query(query)\n",
    "        features = analysis['features']\n",
    "        weights = analysis['weights']\n",
    "        \n",
    "        explanation = {\n",
    "            'query': query,\n",
    "            'gemini_weight': weights['gemini'],\n",
    "            'voyager_weight': weights['voyager'],\n",
    "            'reasoning': []\n",
    "        }\n",
    "        \n",
    "        # Explain each feature's contribution\n",
    "        if features['legal_term_density'] > 5:\n",
    "            explanation['reasoning'].append(\n",
    "                f\"High legal terminology density ({features['legal_term_density']:.1f}%) \"\n",
    "                f\"increased Voyager Law 2 weight by 15%\"\n",
    "            )\n",
    "            \n",
    "        if features['citation_count'] > 0:\n",
    "            explanation['reasoning'].append(\n",
    "                f\"Presence of {features['citation_count']} legal citations \"\n",
    "                f\"increased Voyager Law 2 weight by 15%\"\n",
    "            )\n",
    "            \n",
    "        if features['structural_complexity'] > 0.7:\n",
    "            explanation['reasoning'].append(\n",
    "                f\"High query complexity score ({features['structural_complexity']:.2f}) \"\n",
    "                f\"increased Voyager Law 2 weight by 10%\"\n",
    "            )\n",
    "            \n",
    "        if features['jurisdiction_signals']['specific_court']:\n",
    "            explanation['reasoning'].append(\n",
    "                f\"Specific court reference ({features['jurisdiction_signals']['specific_court']}) \"\n",
    "                f\"increased Voyager Law 2 weight by 10%\"\n",
    "            )\n",
    "            \n",
    "        if not explanation['reasoning']:\n",
    "            explanation['reasoning'].append(\n",
    "                \"Used default weights slightly favoring legal expertise (Voyager: 60%, Gemini: 40%)\"\n",
    "            )\n",
    "            \n",
    "        return explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Fusion RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectFusionRAG:\n",
    "    \"\"\"\n",
    "    Simple weighted combination of retrieval results from both models.\n",
    "    This is a fallback approach if attention-based fusion is problematic.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_path, query_embedding_dim=768, \n",
    "                 device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        print(f\"Initializing LegalSimpleRAG on device: {device}\")\n",
    "        \n",
    "        # Initialize embedding loader\n",
    "        self.embedding_loader = LegalEmbeddingLoader(embedding_path)\n",
    "        self.gemini_embeddings, self.voyager_embeddings, self.metadata = self.embedding_loader.load_embeddings()\n",
    "        \n",
    "        self.query_projection = nn.Linear(768, 1024).to(self.device)\n",
    "\n",
    "        # Get embedding dimensions and verify\n",
    "        gemini_dims, voyager_dims = self.embedding_loader.get_embedding_dimensions()\n",
    "        print(f\"Gemini Embedding Dimensions:\\n{gemini_dims}\")\n",
    "        print(f\"Voyager Embedding Dimensions:\\n{voyager_dims}\")\n",
    "        \n",
    "        # Initialize query analyzer\n",
    "        self.query_analyzer = LegalQueryAnalyzer()\n",
    "        \n",
    "        # Initialize attention fusion model - using fixed version that doesn't rely on dimension dicts\n",
    "        self.attention_model = MultiLevelAttention(output_dim=query_embedding_dim).to(device)\n",
    "        \n",
    "        # Move embeddings to device\n",
    "        for key in self.gemini_embeddings:\n",
    "            self.gemini_embeddings[key] = self.gemini_embeddings[key].to(device)\n",
    "            self.voyager_embeddings[key] = self.voyager_embeddings[key].to(device)\n",
    "            \n",
    "        print(\"LegalSimpleRAG system initialized successfully\")\n",
    "\n",
    "        \n",
    "    def process_query(self, query, top_k=5):\n",
    "        self.query_analyzer = LegalQueryAnalyzer()\n",
    "        # 1. Analyze query for weights\n",
    "        query_analysis = self.query_analyzer.analyze_query(query)\n",
    "        weights = query_analysis['weights']\n",
    "        query_embedding = query_analysis['query_embedding'].to(self.device)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # 2. For each granularity, retrieve from both models separately\n",
    "        for granularity in self.gemini_embeddings.keys():\n",
    "            # Get embeddings\n",
    "            gemini_emb = self.gemini_embeddings[granularity]\n",
    "            linear = nn.Linear(768, 1024)  # Define a linear layer to project gemini_emb to 1024 dimensions\n",
    "            gemini_emb = linear(gemini_emb)\n",
    "            print(f\"Projected gemini_emb shape: {gemini_emb.shape}\") \n",
    "            voyager_emb = self.voyager_embeddings[granularity]\n",
    "            print(f\"voyager_emb shape: {voyager_emb.shape}\")\n",
    "            \n",
    "            if query_embedding.shape[-1] != 768:\n",
    "                print(f\"Warning: Unexpected query_embedding shape {query_embedding.shape}, expected (1, 768)\")\n",
    "            \n",
    "            input_dim = query_embedding.shape[-1]\n",
    "            linear = nn.Linear(input_dim, 1024).to(self.device)\n",
    "            query_embedding = linear(query_embedding)\n",
    "            print(f\"Projected query_embedding shape: {query_embedding.shape}\")\n",
    "            print(f\"Query Embeddings: {query_embedding.shape}\")\n",
    "            # Calculate similarity scores directly\n",
    "            gemini_scores = F.cosine_similarity(\n",
    "                query_embedding.unsqueeze(0),\n",
    "                gemini_emb\n",
    "            )\n",
    "            print(\"gemin Done\")\n",
    "            voyager_scores = F.cosine_similarity(\n",
    "                query_embedding.unsqueeze(0),\n",
    "                voyager_emb\n",
    "            )\n",
    "            print(\"Voyage Done\")\n",
    "            # Weight scores based on query analysis\n",
    "            combined_scores = (\n",
    "                weights['gemini'] * gemini_scores +\n",
    "                weights['voyager'] * voyager_scores\n",
    "            )\n",
    "            print(f\"Shape of combined_scores: {combined_scores.shape}\")\n",
    "            # Flatten combined_scores to 1D\n",
    "            combined_scores = combined_scores.flatten()\n",
    "            print(f\"Shape of combined_scores after Flatten: {combined_scores.shape}\")\n",
    "            # Get top results\n",
    "            top_indices = combined_scores.argsort(descending=True)[:top_k]\n",
    "            # Ensure top_indices are within bounds of combined_scores\n",
    "            top_indices = top_indices[top_indices < combined_scores.shape[0]]\n",
    "\n",
    "            # Now safely access top_results\n",
    "            top_results = combined_scores[top_indices]\n",
    "            # Store results\n",
    "            combined_scores = combined_scores.detach().numpy()\n",
    "            results[granularity] = {\n",
    "                'indices': top_indices,\n",
    "                'scores': combined_scores[top_indices]\n",
    "            }\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example: Processing Legal Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LegalAttentionRAG on device: cpu\n",
      "New_Embeddings_2025\n",
      "New_Embeddings_2025\\chapters\\embeddings_gemini_text-005_chapters_semchunk.parquet\n",
      "\n",
      "Columns in embeddings_gemini_text-005_chapters_semchunk.parquet: ['chunk', 'Embedding']\n",
      "Loaded embeddings_gemini_text-005_chapters_semchunk.parquet (gemini - chapters)\n",
      "New_Embeddings_2025\n",
      "New_Embeddings_2025\\chapters\\embeddings_voyage_per_chapter_semchunked.parquet\n",
      "\n",
      "Columns in embeddings_voyage_per_chapter_semchunked.parquet: ['chunk', 'Embedding']\n",
      "Loaded embeddings_voyage_per_chapter_semchunked.parquet (voyager - chapters)\n",
      "New_Embeddings_2025\n",
      "New_Embeddings_2025\\pages\\embeddings_gemini_text-005_pages_semchunk.parquet\n",
      "\n",
      "Columns in embeddings_gemini_text-005_pages_semchunk.parquet: ['chunk', 'Embedding']\n",
      "Loaded embeddings_gemini_text-005_pages_semchunk.parquet (gemini - pages)\n",
      "New_Embeddings_2025\n",
      "New_Embeddings_2025\\pages\\embeddings_voyage_per_pages_semchunked.parquet\n",
      "\n",
      "Columns in embeddings_voyage_per_pages_semchunked.parquet: ['chunk', 'Embedding']\n",
      "Loaded embeddings_voyage_per_pages_semchunked.parquet (voyager - pages)\n",
      "New_Embeddings_2025\n",
      "New_Embeddings_2025\\sections\\embeddings_gemini_text-005.parquet\n",
      "\n",
      "Columns in embeddings_gemini_text-005.parquet: ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata', 'Embedding']\n",
      "Loaded embeddings_gemini_text-005.parquet (gemini - sections)\n",
      "New_Embeddings_2025\n",
      "New_Embeddings_2025\\sections\\embeddings_voyage.parquet\n",
      "\n",
      "Columns in embeddings_voyage.parquet: ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata', 'Embedding']\n",
      "Loaded embeddings_voyage.parquet (voyager - sections)\n",
      "Gemini Embedding Dimensions:\n",
      "{'chapters': 768, 'pages': 768, 'sections': 768}\n",
      "Voyager Embedding Dimensions:\n",
      "{'chapters': 1024, 'pages': 1024, 'sections': 1024}\n",
      "LegalAttentionRAG system initialized successfully\n",
      "\n",
      "Processing query: 'What are the elements of wire fraud under 18 U.S.C. § 1343?'\n",
      "\n",
      "Query Weight Analysis:\n",
      "Gemini weight: 0.25\n",
      "Voyager weight: 0.75\n",
      "Reasoning:\n",
      "- High legal terminology density (8.3%) increased Voyager Law 2 weight by 15%\n",
      "- Presence of 1 legal citations increased Voyager Law 2 weight by 15%\n",
      "Query embedding shape: torch.Size([1, 768])\n",
      "Model weights: Gemini=0.25, Voyager=0.75\n",
      "Processing granularity: sections\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([1663, 768])\n",
      "New size: 16\n",
      "Granularity Completed: sections\n",
      "Processing granularity: chapters\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([809, 768])\n",
      "New size: 0\n",
      "Granularity Completed: chapters\n",
      "Processing granularity: pages\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([2176, 768])\n",
      "New size: 0\n",
      "Granularity Completed: pages\n",
      "Embedding shapes:\n",
      "New size: 16\n",
      "New size: 0\n",
      "New size: 0\n",
      "\n",
      "#########Top Results#######:\n",
      "{'query_analysis': {'features': {'legal_term_density': 'float', 'citation_count': 'int', 'structural_complexity': 'float', 'query_length': 'int', 'jurisdiction_signals': {'federal': 'bool', 'state': 'bool', 'international': 'bool', 'specific_court': 'NoneType'}}, 'weights': {'gemini': 'float', 'voyager': 'float'}}, 'attention_weights': {'gemini': 'Tensor', 'voyager': 'Tensor', 'combined': 'Tensor'}, 'results': {'sections': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata']}, 'voyager_metadata': {'DataFrame': ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata']}}, 'chapters': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['chunk']}, 'voyager_metadata': {'DataFrame': ['chunk']}}, 'pages': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['chunk']}, 'voyager_metadata': {'DataFrame': ['chunk']}}}}\n",
      "----------END OF RESULTS---------\n",
      "\n",
      "SECTIONS:\n",
      "  1. Section 3044. Complaint-(Rule)... (Score: 0.0403)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3044&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedureContents of complaint; oath, Rule 3.(June 25, 1948, ch. 645, 62 Stat. 816.)...\n",
      "  2. Section 3736. Certiorari-(Rule)... (Score: 0.0341)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3736&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedurePetition to Supreme Court, time, Rule 37(b).(June 25, 1948, ch. 645, 62 Stat. 845.)Editorial NotesReferences in...\n",
      "  3. Section 43. Ã¢ÂÂFront Matter... (Score: 0.0338)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-chapter43-front&num=0&edition=prelim\n",
      "     Content: 18 USC Ch. 43: Front Matter            Result 1 of 1                        ÃÂ              Current2018 Ed. and Supplement V (1/3/2024)2018 Ed. and S...\n",
      "\n",
      "CHAPTERS:\n",
      "  1. Section Any judge or magistrate judge of the United States... (Score: 0.0308)\n",
      "     URL: No URL available\n",
      "     Content: Any judge or magistrate judge of the United States, when ordering a person released under chapter 207 on a condition of his subsequent appearance befo...\n",
      "  2. Section Sec. 3184. Fugitives from foreign country to Unite... (Score: 0.0273)\n",
      "     URL: No URL available\n",
      "     Content: Sec. 3184. Fugitives from foreign country to United States.\n",
      "\n",
      "Whenever there is a treaty or convention for extradition between the United States and an...\n",
      "  3. Section § 965. Verified statements as prerequisite to vess... (Score: 0.0270)\n",
      "     URL: No URL available\n",
      "     Content: § 965. Verified statements as prerequisite to vessel's departure.\n",
      "\n",
      "(a) During a war in which the United States is a neutral nation, every master or pe...\n",
      "\n",
      "PAGES:\n",
      "  1. Section or modify other conditions of parole to the extent... (Score: 0.0322)\n",
      "     URL: No URL available\n",
      "     Content: or modify other conditions of parole to the extent that such conditions are reasonably related to—\n",
      "(1) the nature and circumstances of the offense; an...\n",
      "  2. Section struck out \"Whoever knowingly acts as a referee in... (Score: 0.0291)\n",
      "     URL: No URL available\n",
      "     Content: struck out \"Whoever knowingly acts as a referee in a case in which he is directly or indirectly interested; or\"\n",
      "before \"Whoever, being a\" and \"referee...\n",
      "  3. Section harmonize with congressional intent evidenced by t... (Score: 0.0245)\n",
      "     URL: No URL available\n",
      "     Content: harmonize with congressional intent evidenced by the other sections of this chapter.\n",
      "Minor changes were made in phraseology and unnecessary words were...\n",
      "\n",
      "Processing query: 'Explain the concept of mens rea in criminal law'\n",
      "\n",
      "Query Weight Analysis:\n",
      "Gemini weight: 0.25\n",
      "Voyager weight: 0.75\n",
      "Reasoning:\n",
      "- High legal terminology density (11.1%) increased Voyager Law 2 weight by 15%\n",
      "Query embedding shape: torch.Size([1, 768])\n",
      "Model weights: Gemini=0.25, Voyager=0.75\n",
      "Processing granularity: sections\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([1663, 768])\n",
      "New size: 16\n",
      "Granularity Completed: sections\n",
      "Processing granularity: chapters\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([809, 768])\n",
      "New size: 0\n",
      "Granularity Completed: chapters\n",
      "Processing granularity: pages\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([2176, 768])\n",
      "New size: 0\n",
      "Granularity Completed: pages\n",
      "Embedding shapes:\n",
      "New size: 16\n",
      "New size: 0\n",
      "New size: 0\n",
      "\n",
      "#########Top Results#######:\n",
      "{'query_analysis': {'features': {'legal_term_density': 'float', 'citation_count': 'int', 'structural_complexity': 'float', 'query_length': 'int', 'jurisdiction_signals': {'federal': 'bool', 'state': 'bool', 'international': 'bool', 'specific_court': 'NoneType'}}, 'weights': {'gemini': 'float', 'voyager': 'float'}}, 'attention_weights': {'gemini': 'Tensor', 'voyager': 'Tensor', 'combined': 'Tensor'}, 'results': {'sections': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata']}, 'voyager_metadata': {'DataFrame': ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata']}}, 'chapters': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['chunk']}, 'voyager_metadata': {'DataFrame': ['chunk']}}, 'pages': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['chunk']}, 'voyager_metadata': {'DataFrame': ['chunk']}}}}\n",
      "----------END OF RESULTS---------\n",
      "\n",
      "SECTIONS:\n",
      "  1. Section 3044. Complaint-(Rule)... (Score: 0.0463)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3044&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedureContents of complaint; oath, Rule 3.(June 25, 1948, ch. 645, 62 Stat. 816.)...\n",
      "  2. Section 3736. Certiorari-(Rule)... (Score: 0.0378)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3736&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedurePetition to Supreme Court, time, Rule 37(b).(June 25, 1948, ch. 645, 62 Stat. 845.)Editorial NotesReferences in...\n",
      "  3. Section 3046. Warrant or summons-(Rule)... (Score: 0.0373)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3046&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedureIssuance upon complaint, Rule 4.Issuance upon indictment, Rule 9.Summons on request of government; form; conten...\n",
      "\n",
      "CHAPTERS:\n",
      "  1. Section Any judge or magistrate judge of the United States... (Score: 0.0356)\n",
      "     URL: No URL available\n",
      "     Content: Any judge or magistrate judge of the United States, when ordering a person released under chapter 207 on a condition of his subsequent appearance befo...\n",
      "  2. Section 18 USC Ch. 35: ESCAPE AND RESCUE\n",
      "\n",
      "§ 751. Prisoners... (Score: 0.0312)\n",
      "     URL: No URL available\n",
      "     Content: 18 USC Ch. 35: ESCAPE AND RESCUE\n",
      "\n",
      "§ 751. Prisoners in custody of institution or officer.\n",
      "\n",
      "(a) Whoever escapes or attempts to escape from the custody o...\n",
      "  3. Section 18 USC Ch. 215: Grand Jury\n",
      "\n",
      "§ 3321. Number of gran... (Score: 0.0303)\n",
      "     URL: No URL available\n",
      "     Content: 18 USC Ch. 215: Grand Jury\n",
      "\n",
      "§ 3321. Number of grand jurors; summoning additional jurors.\n",
      "\n",
      "Every grand jury impaneled before any district court shall c...\n",
      "\n",
      "PAGES:\n",
      "  1. Section Section 12 of that act, formerly classified to sec... (Score: 0.0388)\n",
      "     URL: No URL available\n",
      "     Content: Section 12 of that act, formerly classified to section 112 of Title 29, was repealed by act June 25, 1948, and\n",
      "is covered by rule 42(b) of the Federal...\n",
      "  2. Section The National Security Act of 1947, referred to in ... (Score: 0.0313)\n",
      "     URL: No URL available\n",
      "     Content: The National Security Act of 1947, referred to in par. (6), is act July 26, 1947, ch. 343, 61 Stat. 495, which\n",
      "was formerly classified principally to ...\n",
      "  3. Section Secretary of Homeland Security shall issue regulat... (Score: 0.0292)\n",
      "     URL: No URL available\n",
      "     Content: Secretary of Homeland Security shall issue regulations by which any performer may, upon payment\n",
      "[Release Point 118-78]\n",
      "...\n",
      "\n",
      "Processing query: 'What is the difference between Title 18 and Title 26?'\n",
      "\n",
      "Query Weight Analysis:\n",
      "Gemini weight: 0.40\n",
      "Voyager weight: 0.60\n",
      "Reasoning:\n",
      "- Used default weights slightly favoring legal expertise (Voyager: 60%, Gemini: 40%)\n",
      "Query embedding shape: torch.Size([1, 768])\n",
      "Model weights: Gemini=0.40, Voyager=0.60\n",
      "Processing granularity: sections\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([1663, 768])\n",
      "New size: 16\n",
      "Granularity Completed: sections\n",
      "Processing granularity: chapters\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([809, 768])\n",
      "New size: 0\n",
      "Granularity Completed: chapters\n",
      "Processing granularity: pages\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([2176, 768])\n",
      "New size: 0\n",
      "Granularity Completed: pages\n",
      "Embedding shapes:\n",
      "New size: 16\n",
      "New size: 0\n",
      "New size: 0\n",
      "\n",
      "#########Top Results#######:\n",
      "{'query_analysis': {'features': {'legal_term_density': 'float', 'citation_count': 'int', 'structural_complexity': 'float', 'query_length': 'int', 'jurisdiction_signals': {'federal': 'bool', 'state': 'bool', 'international': 'bool', 'specific_court': 'NoneType'}}, 'weights': {'gemini': 'float', 'voyager': 'float'}}, 'attention_weights': {'gemini': 'Tensor', 'voyager': 'Tensor', 'combined': 'Tensor'}, 'results': {'sections': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata']}, 'voyager_metadata': {'DataFrame': ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata']}}, 'chapters': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['chunk']}, 'voyager_metadata': {'DataFrame': ['chunk']}}, 'pages': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['chunk']}, 'voyager_metadata': {'DataFrame': ['chunk']}}}}\n",
      "----------END OF RESULTS---------\n",
      "\n",
      "SECTIONS:\n",
      "  1. Section 3738. Docketing appeal and record-(Rule)... (Score: 0.0222)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3738&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedureFiling record on appeal and docketing proceeding; time, Rule 39(c).(June 25, 1948, ch. 645, 62 Stat. 846.)Edito...\n",
      "  2. Section 3736. Certiorari-(Rule)... (Score: 0.0188)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3736&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedurePetition to Supreme Court, time, Rule 37(b).(June 25, 1948, ch. 645, 62 Stat. 845.)Editorial NotesReferences in...\n",
      "  3. Section 43. Ã¢ÂÂFront Matter... (Score: 0.0177)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-chapter43-front&num=0&edition=prelim\n",
      "     Content: 18 USC Ch. 43: Front Matter            Result 1 of 1                        ÃÂ              Current2018 Ed. and Supplement V (1/3/2024)2018 Ed. and S...\n",
      "\n",
      "CHAPTERS:\n",
      "  1. Section Any judge or magistrate judge of the United States... (Score: 0.0172)\n",
      "     URL: No URL available\n",
      "     Content: Any judge or magistrate judge of the United States, when ordering a person released under chapter 207 on a condition of his subsequent appearance befo...\n",
      "  2. Section § 3006. Assignment of counsel—Rule.\n",
      "\n",
      "§ 3006A. Adeq... (Score: 0.0156)\n",
      "     URL: No URL available\n",
      "     Content: § 3006. Assignment of counsel—Rule.\n",
      "\n",
      "§ 3006A. Adequate representation of defendants.\n",
      "\n",
      "(a) Choice of Plan.—Each United States district court, with the ...\n",
      "  3. Section 18 USC Ch. 215: Grand Jury\n",
      "\n",
      "§ 3321. Number of gran... (Score: 0.0119)\n",
      "     URL: No URL available\n",
      "     Content: 18 USC Ch. 215: Grand Jury\n",
      "\n",
      "§ 3321. Number of grand jurors; summoning additional jurors.\n",
      "\n",
      "Every grand jury impaneled before any district court shall c...\n",
      "\n",
      "PAGES:\n",
      "  1. Section (2) issue a warrant and retake the parolee as prov... (Score: 0.0110)\n",
      "     URL: No URL available\n",
      "     Content: (2) issue a warrant and retake the parolee as provided in this section.\n",
      "(b) Any summons or warrant issued under this section shall be issued by the Co...\n",
      "  2. Section restitution orders, and court's entry of nominal r... (Score: 0.0098)\n",
      "     URL: No URL available\n",
      "     Content: restitution orders, and court's entry of nominal restitution awards where economic circumstances of defendant\n",
      "do not allow for payment of restitution,...\n",
      "  3. Section or modify other conditions of parole to the extent... (Score: 0.0086)\n",
      "     URL: No URL available\n",
      "     Content: or modify other conditions of parole to the extent that such conditions are reasonably related to—\n",
      "(1) the nature and circumstances of the offense; an...\n",
      "\n",
      "Processing query: 'Has the Supreme Court ruled on the constitutionality of 18 U.S.C. § 1512(c)(2)?'\n",
      "\n",
      "Query Weight Analysis:\n",
      "Gemini weight: 0.15\n",
      "Voyager weight: 0.85\n",
      "Reasoning:\n",
      "- High legal terminology density (7.7%) increased Voyager Law 2 weight by 15%\n",
      "- Presence of 1 legal citations increased Voyager Law 2 weight by 15%\n",
      "- Specific court reference (Supreme Court) increased Voyager Law 2 weight by 10%\n",
      "Query embedding shape: torch.Size([1, 768])\n",
      "Model weights: Gemini=0.15, Voyager=0.85\n",
      "Processing granularity: sections\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([1663, 768])\n",
      "New size: 16\n",
      "Granularity Completed: sections\n",
      "Processing granularity: chapters\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([809, 768])\n",
      "New size: 0\n",
      "Granularity Completed: chapters\n",
      "Processing granularity: pages\n",
      "Gemini weights shape: torch.Size([1, 1, 768])\n",
      "Gemini proj shape: torch.Size([2176, 768])\n",
      "New size: 0\n",
      "Granularity Completed: pages\n",
      "Embedding shapes:\n",
      "New size: 16\n",
      "New size: 0\n",
      "New size: 0\n",
      "\n",
      "#########Top Results#######:\n",
      "{'query_analysis': {'features': {'legal_term_density': 'float', 'citation_count': 'int', 'structural_complexity': 'float', 'query_length': 'int', 'jurisdiction_signals': {'federal': 'bool', 'state': 'bool', 'international': 'bool', 'specific_court': 'str'}}, 'weights': {'gemini': 'float', 'voyager': 'float'}}, 'attention_weights': {'gemini': 'Tensor', 'voyager': 'Tensor', 'combined': 'Tensor'}, 'results': {'sections': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata']}, 'voyager_metadata': {'DataFrame': ['Section', 'Url', 'Content', 'Metadata', 'Processed_Content', 'Processed_Section', 'Processed_Metadata']}}, 'chapters': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['chunk']}, 'voyager_metadata': {'DataFrame': ['chunk']}}, 'pages': {'indices': 'ndarray', 'scores': 'ndarray', 'gemini_metadata': {'DataFrame': ['chunk']}, 'voyager_metadata': {'DataFrame': ['chunk']}}}}\n",
      "----------END OF RESULTS---------\n",
      "\n",
      "SECTIONS:\n",
      "  1. Section 3044. Complaint-(Rule)... (Score: 0.0649)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3044&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedureContents of complaint; oath, Rule 3.(June 25, 1948, ch. 645, 62 Stat. 816.)...\n",
      "  2. Section 3008. Service and filing of papers-(Rule)... (Score: 0.0576)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3008&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedureRequirement and manner of service; notice of orders; filing papers, rule 49.(June 25, 1948, ch. 645, 62 Stat. 8...\n",
      "  3. Section 3739. Supervision-(Rule)... (Score: 0.0569)\n",
      "     URL: https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section3739&num=0&edition=prelim\n",
      "     Content: See Federal Rules of Criminal ProcedureControl and supervision in appellate court, Rule 39(a).(June 25, 1948, ch. 645, 62 Stat. 846.)Editorial NotesRe...\n",
      "\n",
      "CHAPTERS:\n",
      "  1. Section Any judge or magistrate judge of the United States... (Score: 0.0497)\n",
      "     URL: No URL available\n",
      "     Content: Any judge or magistrate judge of the United States, when ordering a person released under chapter 207 on a condition of his subsequent appearance befo...\n",
      "  2. Section § 1835. Orders to preserve confidentiality.\n",
      "\n",
      "(a) I... (Score: 0.0429)\n",
      "     URL: No URL available\n",
      "     Content: § 1835. Orders to preserve confidentiality.\n",
      "\n",
      "(a) In General.—In any prosecution or other proceeding under this chapter, the court shall enter such ord...\n",
      "  3. Section 18 USC Ch. 319: National Institute of Corrections\n",
      "... (Score: 0.0396)\n",
      "     URL: No URL available\n",
      "     Content: 18 USC Ch. 319: National Institute of Corrections\n",
      "\n",
      "CHAPTER 319—NATIONAL INSTITUTE OF CORRECTIONS\n",
      "\n",
      "Sec. 4351. Establishment; Advisory Board; appointmen...\n",
      "\n",
      "PAGES:\n",
      "  1. Section Section 12 of that act, formerly classified to sec... (Score: 0.0560)\n",
      "     URL: No URL available\n",
      "     Content: Section 12 of that act, formerly classified to section 112 of Title 29, was repealed by act June 25, 1948, and\n",
      "is covered by rule 42(b) of the Federal...\n",
      "  2. Section or modify other conditions of parole to the extent... (Score: 0.0479)\n",
      "     URL: No URL available\n",
      "     Content: or modify other conditions of parole to the extent that such conditions are reasonably related to—\n",
      "(1) the nature and circumstances of the offense; an...\n",
      "  3. Section paragraphs 4 and 5, respectively.\n",
      "RICHARD NIXON.  ... (Score: 0.0386)\n",
      "     URL: No URL available\n",
      "     Content: paragraphs 4 and 5, respectively.\n",
      "RICHARD NIXON.      \n",
      "§3194. Transportation of fugitive by receiving agent\n",
      "Any agent appointed as provided in section...\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the complete system\n",
    "def example_usage():\n",
    "    # Initialize the system\n",
    "    legal_rag = LegalAttentionRAG(embedding_path=\"New_Embeddings_2025\")\n",
    "    \n",
    "    # Example queries representing different types of legal questions\n",
    "    queries = [\n",
    "        \"What are the elements of wire fraud under 18 U.S.C. § 1343?\",\n",
    "        \"Explain the concept of mens rea in criminal law\",\n",
    "        \"What is the difference between Title 18 and Title 26?\",\n",
    "        \"Has the Supreme Court ruled on the constitutionality of 18 U.S.C. § 1512(c)(2)?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nProcessing query: '{query}'\")\n",
    "        \n",
    "        # Get explanation of weight determination\n",
    "        explanation = legal_rag.explain_weights(query)\n",
    "        print(\"\\nQuery Weight Analysis:\")\n",
    "        print(f\"Gemini weight: {explanation['gemini_weight']:.2f}\")\n",
    "        print(f\"Voyager weight: {explanation['voyager_weight']:.2f}\")\n",
    "        print(\"Reasoning:\")\n",
    "        for reason in explanation['reasoning']:\n",
    "            print(f\"- {reason}\")\n",
    "            \n",
    "        # Process query and get results using Attention and Direct fusion RAG\n",
    "        technique= \"Attention\"\n",
    "        import pandas as pd\n",
    "\n",
    "        def get_dict_skeleton_with_df(d):\n",
    "            if isinstance(d, dict):\n",
    "                return {k: get_dict_skeleton_with_df(v) for k, v in d.items()}\n",
    "            elif isinstance(d, list):\n",
    "                return [get_dict_skeleton_with_df(d[0]) if d else []]  # Handle lists\n",
    "            elif isinstance(d, pd.DataFrame):\n",
    "                return {\"DataFrame\": list(d.columns)}  # Extract DataFrame column names\n",
    "            else:\n",
    "                return type(d).__name__  # Get the type of the value\n",
    "        if technique == \"Direct\":\n",
    "\n",
    "            direct_fusion_rag = DirectFusionRAG(embedding_path=\"New_Embeddings_2025\")  # Initialize DirectFusionRAG\n",
    "            results = direct_fusion_rag.process_query(query)\n",
    "            print(results)\n",
    "            print(\"Direct RAG DONE\")\n",
    "            print(\"\\nTop Results:\")\n",
    "            for granularity, data in results.items():\n",
    "                print(f\"\\n{granularity.upper()}:\")\n",
    "                for i, index in enumerate(data['indices'].tolist()):  # Convert tensor to list\n",
    "                    score = data['scores'][i]\n",
    "                    print(f\"  {i+1}. Index: {index} (Score: {score:.4f})\")\n",
    "\n",
    "        if technique==\"Attention\":\n",
    "            results = legal_rag.process_query(query, top_k=3)\n",
    "            print(\"\\n#########Top Results#######:\")\n",
    "            print(get_dict_skeleton_with_df(results))\n",
    "            print(\"----------END OF RESULTS---------\")\n",
    "        # Display top results from different granularities\n",
    "            for granularity in results['results']:\n",
    "                print(f\"\\n{granularity.upper()}:\")\n",
    "                for i in range(len(results['results'][granularity]['indices'])):\n",
    "                    score = results['results'][granularity]['scores'][i]\n",
    "                    # Get the actual index from indices array\n",
    "                    idx = results['results'][granularity]['indices'][i]\n",
    "                    \n",
    "                    # Access metadata using proper keys from DataFrame structure\n",
    "                    metadata = results['results'][granularity]['voyager_metadata'].iloc[i]\n",
    "                    \n",
    "                    # Use .get() with fallback values for missing keys\n",
    "                    print(f\"  {i+1}. Section {metadata.get('Section', metadata.get('chunk', 'N/A'))[:50]}... (Score: {score:.4f})\")\n",
    "                    print(f\"     URL: {metadata.get('Url', 'No URL available')}\")\n",
    "                    print(f\"     Content: {metadata.get('Content', metadata.get('chunk', 'No text available'))[:150]}...\")\n",
    "\n",
    "\n",
    "\n",
    "example_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
