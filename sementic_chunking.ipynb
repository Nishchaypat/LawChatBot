{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain openai sentence-transformers\n",
    "!pip install langchain sentence-transformers pandas nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/isaacus-dev/semchunk.git\n",
      "  Cloning https://github.com/isaacus-dev/semchunk.git to c:\\users\\mkolla1\\appdata\\local\\temp\\pip-req-build-cg4vavib\n",
      "  Resolved https://github.com/isaacus-dev/semchunk.git to commit 9945642bca366925faf5bd969c2cf1bab1661725\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: mpire[dill] in c:\\users\\mkolla1\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from semchunk==3.0.1) (2.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mkolla1\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from semchunk==3.0.1) (4.66.1)\n",
      "Requirement already satisfied: pygments>=2.0 in c:\\users\\mkolla1\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mpire[dill]->semchunk==3.0.1) (2.14.0)\n",
      "Requirement already satisfied: pywin32>=301 in c:\\users\\mkolla1\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mpire[dill]->semchunk==3.0.1) (305)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\mkolla1\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mpire[dill]->semchunk==3.0.1) (0.70.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\mkolla1\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm->semchunk==3.0.1) (0.4.6)\n",
      "Requirement already satisfied: dill>=0.3.9 in c:\\users\\mkolla1\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from multiprocess->mpire[dill]->semchunk==3.0.1) (0.3.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/isaacus-dev/semchunk.git 'C:\\Users\\mkolla1\\AppData\\Local\\Temp\\pip-req-build-cg4vavib'\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: C:\\Users\\mkolla1\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install semchunk\n",
    "!pip install git+https://github.com/isaacus-dev/semchunk.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Author 1\n",
      "Name: Manish Kolla\n",
      "Major: Computer Science\n",
      "-------------------\n",
      "-------------------\n",
      "Abstract:\n",
      "-------------------\n",
      "-------------------\n",
      "CareerWide is an AI-powered recruitment platform designed to revolutionize the hiring process for both students and recruiters. By leveraging advanced AI, CareerWide streamlines recruitment through personalized, merit-based candidate matching and removes biases related to ethnicity, gender, and other personal\n",
      "-------------------\n",
      "-------------------\n",
      "characteristics. For students, the platform offers features like automated resume enhancement, personalized skill development calendars, and AI-driven insights to improve career prospects. Students can also express their individuality by selecting avatars, gaining visibility in a unique, inclusive way.\n",
      "-------------------\n",
      "-------------------\n",
      "For recruiters, CareerWide provides advanced filtering tools that focus on skills, GPA, and other relevant criteria, simplifying the search for the best candidates.\n",
      "-------------------\n",
      "-------------------\n",
      "Author 2\n",
      "-------------------\n",
      "-------------------\n",
      "Name: Nishchay Patel\n",
      "-------------------\n",
      "-------------------\n",
      "Major: Computer Science. The platform also supports virtual career fairs, minimizing travel and promoting sustainability. With its focus on equity, efficiency, and innovation, CareerWide is transforming recruitment into a fairer, more sustainable, and inclusive process for all.\n",
      "-------------------\n",
      "-------------------\n",
      "Faculty Sponsor: \n",
      "Name: Dr. Parag Tamhankar\n",
      "Department: Computer Science\n",
      "Email: ptamhankar@gsu.edu\n",
      "-------------------\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import semchunk\n",
    "import tiktoken\n",
    "from semchunk import chunkerify\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Load a pre-trained embedding model (no API key required)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize Semantic Chunker\n",
    "chunker = semchunk.chunkerify('gpt-4', max_token_chars = None,chunk_size =50)  # Adjust threshold as needed\n",
    "#chunker = semchunk.chunkerify(tiktoken.encoding_for_model('gpt-4'), max_token_chars = None,chunk_size =50)  # Adjust threshold as needed\n",
    "# Process and chunk the law text\n",
    "text= \"\"\" Author 1\n",
    "Name: Manish Kolla\n",
    "Major: Computer Science\n",
    "\n",
    "Abstract:\n",
    "CareerWide is an AI-powered recruitment platform designed to revolutionize the hiring process for both students and recruiters. By leveraging advanced AI, CareerWide streamlines recruitment through personalized, merit-based candidate matching and removes biases related to ethnicity, gender, and other personal characteristics. For students, the platform offers features like automated resume enhancement, personalized skill development calendars, and AI-driven insights to improve career prospects. Students can also express their individuality by selecting avatars, gaining visibility in a unique, inclusive way. For recruiters, CareerWide provides advanced filtering tools that focus on skills, GPA, and other relevant criteria, simplifying the search for the best candidates.      Author 2\n",
    "Name: Nishchay Patel\n",
    "Major: Computer Science. The platform also supports virtual career fairs, minimizing travel and promoting sustainability. With its focus on equity, efficiency, and innovation, CareerWide is transforming recruitment into a fairer, more sustainable, and inclusive process for all.\n",
    "Faculty Sponsor: \n",
    "Name: Dr. Parag Tamhankar\n",
    "Department: Computer Science\n",
    "Email: ptamhankar@gsu.edu\n",
    "\n",
    "     \"\"\"\n",
    "chunks = chunker(text)\n",
    "for x in chunks:\n",
    "  print(x)\n",
    "  print('-------------------')\n",
    "  print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3647.8250311332504\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Title18_Pages_converted.csv\"  # Change based on your file format\n",
    "df = pd.read_csv(file_path)  \n",
    "length=[]\n",
    "for x in df['Text']:\n",
    "    length.append(len(x))\n",
    "print(sum(length)/len(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import semchunk\n",
    "from semchunk import chunkerify\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the law text from a CSV file\n",
    "file_path = \"Title18_Pages_converted.csv\"  # Change based on your file format\n",
    "df = pd.read_csv(file_path)  \n",
    "\n",
    "# Assume each page of the law text is in a column named 'content'\n",
    "documents = df[\"Text\"].tolist()\n",
    "\n",
    "# Load a pre-trained embedding model (no API key required)\n",
    "#embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize Semantic Chunker\n",
    "chunker = semchunk.chunkerify('gpt-4', max_token_chars = None,chunk_size =1000)  # Adjust threshold as needed\n",
    "\n",
    "# Process and chunk the law text\n",
    "chunks = chunker(documents)\n",
    "\n",
    "# Convert chunked text into a DataFrame\n",
    "chunked_data = []\n",
    "for x in chunks:\n",
    "    for y in x: \n",
    "        chunked_data.append([y])\n",
    "\n",
    "chunked_df = pd.DataFrame(chunked_data, columns=[\"chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2176, 1)\n"
     ]
    }
   ],
   "source": [
    "print(chunked_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344\n",
      "<class 'str'>\n",
      "Pub. L. 112–154, title VI, §601(a), Aug. 6, 2012, 126 Stat. 1195, provided that:\n",
      "\"(1) \n",
      ".—The purpose of this section [amending this section and section 2413 of Title 38, Veterans'\n",
      "PURPOSE\n",
      "Benefits] is to provide necessary and proper support for the recruitment and retention of the Armed Forces and\n",
      "militia employed in the service of the United States by protecting the dignity of the service of the members of\n",
      "such Forces and militia, and by protecting the privacy of their immediate family members and other attendees\n",
      "during funeral services for such members.\n",
      "\"(2) \n",
      ".—Congress finds that this section is a necessary and proper\n",
      "CONSTITUTIONAL AUTHORITY\n",
      "exercise of its powers under the Constitution, article I, section 8, paragraphs 1, 12, 13, 14, 16, and 18, to\n",
      "provide for the common defense, raise and support armies, provide and maintain a navy, make rules for the\n",
      "government and regulation of the land and naval forces, and provide for organizing and governing such part of\n",
      "the militia as may be employed in the service of the United States.\"\n",
      "§1389. Prohibition on attacks on United States servicemen on account of service\n",
      "(a) \n",
      ".—Whoever knowingly assaults or batters a United States serviceman or an\n",
      "IN GENERAL\n",
      "immediate family member of a United States serviceman, or who knowingly destroys or injures the\n",
      "property of such serviceman or immediate family member, on account of the military service of that\n",
      "serviceman or status of that individual as a United States serviceman, or who attempts or conspires to\n",
      "do so, shall—\n",
      "(1) in the case of a simple assault, or destruction or injury to property in which the damage or\n",
      "attempted damage to such property is not more than $500, be fined under this title in an amount\n",
      "not less than $500 nor more than $10,000 and imprisoned not more than 2 years;\n",
      "(2) in the case of destruction or injury to property in which the damage or attempted damage to\n",
      "such property is more than $500, be fined under this title in an amount not less than $1000 nor\n",
      "more than $100,000 and imprisoned not more than 5 years; and\n",
      "(3) in the case of a battery, or an assault resulting in bodily injury, be fined under this title in an\n",
      "amount not less than $2500 and imprisoned not less than 6 months nor more than 10 years.\n",
      "(b) \n",
      ".—This section shall not apply to conduct by a person who is subject to the\n",
      "EXCEPTION\n",
      "Uniform Code of Military Justice.\n",
      "(c) \n",
      ".—In this section—\n",
      "DEFINITIONS\n",
      "(1) the term \"Armed Forces\" has the meaning given that term in section 1388;\n",
      "(2) the term \"immediate family member\" has the meaning given that term in section 115; and\n",
      "(3) the term \"United States serviceman\"—\n",
      "(A) means a member of the Armed Forces; and\n",
      "(B) includes a former member of the Armed Forces during the 5-year period beginning on the\n",
      "date of the discharge from the Armed Forces of that member of the Armed Forces.\n",
      "(Added Pub. L. 111–84, div. E, §4712(a), Oct. 28, 2009, 123 Stat. 2842.)\n",
      "EDITORIAL NOTES\n",
      "REFERENCES IN TEXT\n",
      "The Uniform Code of Military Justice, referred to in subsec. (b), is classified generally to chapter 47 (§801\n",
      "et seq.) of Title 10, Armed Forces.\n",
      "[CHAPTER 68—REPEALED]\n",
      "[§§1401 to 1407. Repealed. Pub. L. 91–513, title III, §1101(b)(1)(A), Oct. 27, 1970,\n",
      "84 Stat. 1292]\n",
      "Section 1401, acts July 18, 1956, ch. 629, title II, §201, 70 Stat. 572; July 12, 1960, Pub. L. 86–624, §13(a),\n",
      "[Release Point 118-78]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "num=random.randint(0, chunked_df.shape[0])\n",
    "print(len(chunked_df['chunk'][num]))\n",
    "print(type(chunked_df['chunk'][num]))\n",
    "print(chunked_df['chunk'][num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Semantic chunking completed! Saved to 'chunked_title_18semchunk.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the results into a new CSV file\n",
    "chunked_df.to_csv(\"chunked_title_18semchunk.csv\", index=False)\n",
    "print(\"✅ Semantic chunking completed! Saved to 'chunked_title_18semchunk.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkolla1\\AppData\\Local\\Temp\\ipykernel_33704\\1983244083.py:13: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Semantic chunking completed! Saved to 'chunked_title_18.csv'.\n",
      "(7706, 1)\n",
      "                                               chunk\n",
      "0  6001\\nImmunity of Witnesses\\nV.\\n5001\\nCorrect...\n",
      "1  37\\n756, 3058\\n38\\nT. 22 §465\\n39\\n5, 3241\\n51...\n",
      "2  79\\n1003\\n80\\n287, 1001\\n81\\n289\\n82\\n641, 136...\n",
      "3  123\\n912\\n124\\n211\\n125\\n543\\n126\\n541\\n127\\n1...\n",
      "4  199\\n205\\n200\\n204\\n201\\n1913\\n202\\n216\\n203\\n...\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Title 18 law text from CSV\n",
    "file_path = \"Title18_Pages_converted.csv\"  # Adjust for JSON/Excel if needed\n",
    "df = pd.read_csv(file_path)  \n",
    "\n",
    "# Assume each page of the law text is in a column named 'content'\n",
    "documents = df[\"Text\"].tolist()\n",
    "\n",
    "# Use Hugging Face embeddings (local model, no API key needed)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize RecursiveCharacterTextSplitter for semantic-aware chunking\n",
    "chunker = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Process and chunk the law text\n",
    "chunks = []\n",
    "for doc in documents:\n",
    "    chunks.extend(chunker.split_text(doc))\n",
    "\n",
    "# Convert chunked text into a DataFrame\n",
    "chunked_df = pd.DataFrame({\"chunk\": chunks})\n",
    "\n",
    "# Save the results into a new CSV file\n",
    "chunked_df.to_csv(\"chunked_title_18RCTS.csv\", index=False)\n",
    "\n",
    "print(\"✅ Semantic chunking completed! Saved to 'chunked_title_18.csv'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(chunked_df.shape)\n",
    "print(chunked_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(p) Nothing in this section or sections 2248, 2259, 2264, 2327, 3663, and 3663A and arising out of\n",
      "the application of such sections, shall be construed to create a cause of action not otherwise\n",
      "authorized in favor of any person against the United States or any officer or employee of the United\n",
      "States.\n",
      "(Added Pub. L. 97–291, §5(a), Oct. 12, 1982, 96 Stat. 1255, §3580; renumbered §3664, Pub. L.\n",
      "98–473, title II, §212(a)(1), Oct. 12, 1984, 98 Stat. 1987; amended Pub. L. 101–647, title XXXV,\n",
      "§3596, Nov. 29, 1990, 104 Stat. 4931; Pub. L. 104–132, title II, §206(a), Apr. 24, 1996, 110 Stat.\n",
      "1232; Pub. L. 107–273, div. B, title IV, §4002(e)(1), Nov. 2, 2002, 116 Stat. 1810.)\n",
      "EDITORIAL NOTES\n",
      "REFERENCES IN TEXT\n",
      "The Federal Rules of Criminal Procedure, referred to in subsecs. (c) and (o)(1)(A), are set out in the\n",
      "Appendix to this title.\n",
      "AMENDMENTS\n",
      "2002—Subsec. (o)(1)(C). Pub. L. 107–273 substituted \"subsection (d)(5)\" for \"section 3664(d)(3)\".\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(chunked_df['chunk'][random.randint(0, chunked_df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export chunked text to a new CSV file\n",
    "chunked_df.to_csv(\"chunked_title_18.csv\", index=False)\n",
    "\n",
    "print(\"Chunking completed! Saved to 'chunked_title_18.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
