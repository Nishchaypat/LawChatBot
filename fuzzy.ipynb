{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "import tiktoken\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import vertexai\n",
    "from typing import List, Dict, Union, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LegalQueryAnalyzer.__init__() got an unexpected keyword argument 'use_gemini'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 596\u001b[0m\n\u001b[1;32m    587\u001b[0m         gemini_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m voyager_weight\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini\u001b[39m\u001b[38;5;124m'\u001b[39m: gemini_weight,\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoyager\u001b[39m\u001b[38;5;124m'\u001b[39m: voyager_weight\n\u001b[1;32m    592\u001b[0m         }\n\u001b[0;32m--> 596\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mLegalQueryAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_gemini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: LegalQueryAnalyzer.__init__() got an unexpected keyword argument 'use_gemini'"
     ]
    }
   ],
   "source": [
    "class LegalQueryAnalyzer:\n",
    "    \"\"\"\n",
    "    Advanced legal query analyzer using fuzzy logic to determine query intent and optimize \n",
    "    the weighting between general-purpose and specialized legal language models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, legal_terms=None, citation_patterns=None):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with necessary resources and fuzzy logic parameters.\n",
    "        \n",
    "        Args:\n",
    "            legal_terms: List of legal terminology for detection\n",
    "            citation_patterns: List of regex patterns for legal citations\n",
    "        \"\"\"\n",
    "        self.legal_terms = legal_terms or self._get_default_legal_terms()\n",
    "        self.citation_patterns = citation_patterns or self._get_default_citation_patterns()\n",
    "        \n",
    "        # Initialize fuzzy logic system\n",
    "        self._initialize_fuzzy_system()\n",
    "        \n",
    "    def _get_default_legal_terms(self):\n",
    "        \"\"\"Return default list of legal terms if none provided.\"\"\"\n",
    "        return [\n",
    "            \"plaintiff\", \"defendant\", \"jurisdiction\", \"statutory\", \"litigation\", \"tort\",\n",
    "            \"appellant\", \"respondent\", \"judicial\", \"injunction\", \"statute\", \"precedent\",\n",
    "            \"adjudication\", \"jurisprudence\", \"liability\", \"damages\", \"breach\", \"discovery\",\n",
    "            \"complaint\", \"pleading\", \"deposition\", \"affidavit\", \"indictment\", \"subpoena\",\n",
    "            \"writ\", \"motion\", \"contract\", \"negligence\", \"remedy\", \"verdict\", \"hearing\",\n",
    "            \"acquittal\", \"habeas corpus\", \"malpractice\", \"pro bono\", \"due process\",\n",
    "            \"prima facie\", \"de facto\", \"de jure\", \"en banc\", \"amicus curiae\"\n",
    "        ]\n",
    "        \n",
    "    def _get_default_citation_patterns(self):\n",
    "        \"\"\"Return default regex patterns for legal citations if none provided.\"\"\"\n",
    "        return [\n",
    "            r'\\d+\\s+U\\.S\\.\\s+\\d+',              # US Reports citation\n",
    "            r'\\d+\\s+S\\.Ct\\.\\s+\\d+',             # Supreme Court Reporter\n",
    "            r'\\d+\\s+F\\.\\d[d|r]d?\\.\\s+\\d+',      # Federal Reporter\n",
    "            r'\\d+\\s+F\\.Supp\\.\\d?[d]?\\s+\\d+',    # Federal Supplement\n",
    "            r'\\d+\\s+[A-Za-z\\.]+\\s+\\d+',         # Generic reporter citation\n",
    "            r'[A-Za-z]+\\sv\\.\\s[A-Za-z]+',       # Case name (v. format)\n",
    "            r'[0-9]{1,4}\\s[A-Za-z\\.]{1,15}\\s[0-9]{1,4}' # General citation format\n",
    "        ]\n",
    "        \n",
    "    def _initialize_fuzzy_system(self):\n",
    "        \"\"\"Initialize the fuzzy inference system parameters and membership functions.\"\"\"\n",
    "        # Define fuzzy set parameters for each feature\n",
    "        self.fuzzy_sets = {\n",
    "            'legal_term_density': {\n",
    "                'low': {'a': 0, 'b': 0, 'c': 1, 'd': 2},         # Tighter low range\n",
    "                'medium': {'a': 1, 'b': 3, 'c': 5},              # More defined medium\n",
    "                'high': {'a': 4, 'b': 6, 'c': 100, 'd': 100}     # Lower threshold for high\n",
    "            },\n",
    "            'citation_count': {\n",
    "                'none': {'a': 0, 'b': 0, 'c': 0.1},              # Stricter none definition\n",
    "                'few': {'a': 0, 'b': 0.5, 'c': 1.5},             # Narrower few range\n",
    "                'many': {'a': 1, 'b': 2, 'c': 100, 'd': 100}     # Lower threshold for many\n",
    "            },\n",
    "            'structural_complexity': {\n",
    "                'simple': {'a': 0, 'b': 0, 'c': 0.2, 'd': 0.3},  # Tighter simple range\n",
    "                'moderate': {'a': 0.2, 'b': 0.4, 'c': 0.6},      # More defined moderate\n",
    "                'complex': {'a': 0.5, 'b': 0.7, 'c': 1.0, 'd': 1.0}  # Slightly lower threshold\n",
    "            },\n",
    "            'jurisdiction_score': {\n",
    "                'general': {'a': 0, 'b': 0, 'c': 0.2, 'd': 0.3}, # Tighter general range\n",
    "                'specific': {'a': 0.2, 'b': 0.4, 'c': 1.0, 'd': 1.0}  # Lower threshold for specific\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Define fuzzy inference rules\n",
    "        # Define fuzzy inference rules with more extreme weighting\n",
    "        self.fuzzy_rules = [\n",
    "            # Rules favoring strong legal specialization (high Voyager weight)\n",
    "            {'conditions': {'legal_term_density': 'high', 'citation_count': 'many'}, \n",
    "            'weight': 0.98},  \n",
    "            {'conditions': {'legal_term_density': 'high', 'structural_complexity': 'complex'}, \n",
    "            'weight': 0.86},\n",
    "            {'conditions': {'citation_count': 'many', 'structural_complexity': 'complex'}, \n",
    "            'weight': 0.89}, \n",
    "            {'conditions': {'legal_term_density': 'medium', 'citation_count': 'few', \n",
    "                        'jurisdiction_score': 'specific'}, \n",
    "            'weight': 0.82},\n",
    "            \n",
    "            # Rules for moderate legal specialization\n",
    "            {'conditions': {'legal_term_density': 'medium', 'structural_complexity': 'moderate'}, \n",
    "            'weight': 0.62},\n",
    "            {'conditions': {'legal_term_density': 'low', 'citation_count': 'few'}, \n",
    "            'weight': 0.53}, \n",
    "            \n",
    "            # Rules favoring general knowledge (high Gemini weight)\n",
    "            {'conditions': {'legal_term_density': 'low', 'citation_count': 'none', \n",
    "                        'structural_complexity': 'simple'}, \n",
    "            'weight': 0.22},  # Decreased from 0.35 (lower Voyager = higher Gemini)\n",
    "            {'conditions': {'legal_term_density': 'low', 'jurisdiction_score': 'general'}, \n",
    "            'weight': 0.18}   # Decreased from 0.40\n",
    "        ]\n",
    "\n",
    "        \n",
    "    def analyze_query(self, query):\n",
    "        \"\"\"\n",
    "        Analyze query characteristics using fuzzy logic to determine model weights.\n",
    "        \n",
    "        Args:\n",
    "            query: The input query string\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with features, fuzzy memberships, weights, and query embedding\n",
    "        \"\"\"\n",
    "        # Extract features without using spaCy\n",
    "        features = {\n",
    "            'legal_term_density': self._calculate_legal_term_density(query),\n",
    "            'citation_count': self._count_citations(query),\n",
    "            'structural_complexity': self._assess_complexity(query),\n",
    "            'query_length': len(self._tokenize(query)),\n",
    "            'jurisdiction_signals': self._detect_jurisdiction(query)\n",
    "        }\n",
    "        \n",
    "        # Add jurisdiction score from signals\n",
    "        features['jurisdiction_score'] = features['jurisdiction_signals']['jurisdiction_score']\n",
    "        \n",
    "        # Calculate fuzzy memberships for each feature\n",
    "        fuzzy_memberships = self._fuzzify_features(features)\n",
    "        \n",
    "        # Apply fuzzy inference to determine weights\n",
    "        weights = self._fuzzy_inference(fuzzy_memberships)\n",
    "        \n",
    "        return {\n",
    "            'features': features,\n",
    "            'fuzzy_memberships': fuzzy_memberships,\n",
    "            'weights': weights,\n",
    "            'query_embedding': None\n",
    "        }\n",
    "    \n",
    "    def _tokenize(self, text):\n",
    "        \"\"\"Tokenize text using the appropriate tokenizer.\"\"\"\n",
    "        if self.use_gemini:\n",
    "            return self.tokenizer.encode(text)\n",
    "        else:\n",
    "            return self.tokenizer.tokenize(text)\n",
    "    \n",
    "    def _calculate_legal_term_density(self, query):\n",
    "        \"\"\"\n",
    "        Calculate the density of legal terminology in the query using fuzzy matching.\n",
    "        \n",
    "        Args:\n",
    "            query: The input query string\n",
    "            \n",
    "        Returns:\n",
    "            Percentage of query that consists of legal terminology\n",
    "        \"\"\"\n",
    "        # Normalize query\n",
    "        query_lower = query.lower()\n",
    "        words = query_lower.split()\n",
    "        total_tokens = len(words)\n",
    "        \n",
    "        if total_tokens == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Count exact matches\n",
    "        exact_matches = sum(1 for term in self.legal_terms if term.lower() in query_lower)\n",
    "        \n",
    "        # Count fuzzy matches (with reduced weight)\n",
    "        fuzzy_matches = 0\n",
    "        for word in words:\n",
    "                \n",
    "            for term in self.legal_terms:\n",
    "                term_lower = term.lower()\n",
    "                # Skip if already counted as exact match\n",
    "                if term_lower in query_lower:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate similarity\n",
    "                similarity = self._string_similarity(word, term_lower)\n",
    "                if similarity >= 0.85:\n",
    "                    fuzzy_matches += similarity * 0.7  # Weight fuzzy matches less\n",
    "                    break\n",
    "        \n",
    "        # Calculate weighted density\n",
    "        legal_term_count = exact_matches + fuzzy_matches\n",
    "        return (legal_term_count / total_tokens) * 100\n",
    "    \n",
    "    def _string_similarity(self, s1, s2):\n",
    "        \"\"\"\n",
    "        Calculate string similarity using Levenshtein distance ratio.\n",
    "        \n",
    "        Args:\n",
    "            s1, s2: Strings to compare\n",
    "            \n",
    "        Returns:\n",
    "            Similarity score between 0-1\n",
    "        \"\"\"\n",
    "        # Simple implementation - in production, use libraries like rapidfuzz\n",
    "        if not s1 or not s2:\n",
    "            return 0\n",
    "            \n",
    "        # Calculate Levenshtein distance\n",
    "        len_s1, len_s2 = len(s1), len(s2)\n",
    "        if len_s1 > len_s2:\n",
    "            s1, s2 = s2, s1\n",
    "            len_s1, len_s2 = len_s2, len_s1\n",
    "            \n",
    "        # Initialize distance matrix\n",
    "        d = list(range(len_s1 + 1))\n",
    "        for i in range(1, len_s2 + 1):\n",
    "            prev_d = d.copy()\n",
    "            d[0] = i\n",
    "            for j in range(1, len_s1 + 1):\n",
    "                cost = 0 if s2[i-1] == s1[j-1] else 1\n",
    "                d[j] = min(prev_d[j] + 1,      # deletion\n",
    "                          d[j-1] + 1,         # insertion\n",
    "                          prev_d[j-1] + cost)  # substitution\n",
    "                          \n",
    "        # Convert distance to similarity ratio\n",
    "        max_len = max(len_s1, len_s2)\n",
    "        if max_len == 0:\n",
    "            return 1.0\n",
    "        return 1.0 - (d[-1] / max_len)\n",
    "    \n",
    "    def _count_citations(self, query):\n",
    "        \"\"\"\n",
    "        Count legal citations in the query with fuzzy pattern recognition.\n",
    "        \n",
    "        Args:\n",
    "            query: The input query string\n",
    "            \n",
    "        Returns:\n",
    "            Weighted count of legal citations\n",
    "        \"\"\"\n",
    "        # Count exact citation matches\n",
    "        exact_count = sum(len(re.findall(pattern, query)) for pattern in self.citation_patterns)\n",
    "        \n",
    "        # Look for potential malformed citations\n",
    "        potential_citations = re.findall(r'(\\d+\\s*[A-Za-z\\.]+\\s*\\d+)', query)\n",
    "        fuzzy_count = 0\n",
    "        \n",
    "        for potential in potential_citations:\n",
    "            # Skip if already counted as exact match\n",
    "            if any(re.search(pattern, potential) for pattern in self.citation_patterns):\n",
    "                continue\n",
    "                \n",
    "            # Check if it resembles a citation format\n",
    "            if re.search(r'\\d+\\s*[A-Za-z\\.]+\\s*\\d+', potential):\n",
    "                fuzzy_count += 0.5  # Partial credit\n",
    "        \n",
    "        return exact_count + fuzzy_count\n",
    "    \n",
    "    def _assess_complexity(self, query):\n",
    "        \"\"\"\n",
    "        Assess the structural complexity of the query using linguistic features.\n",
    "        \n",
    "        Args:\n",
    "            query: The input query string\n",
    "            \n",
    "        Returns:\n",
    "            Complexity score from 0-1\n",
    "        \"\"\"\n",
    "        # Legal clause markers\n",
    "        clause_markers = [\n",
    "            \"if\", \"when\", \"whereas\", \"notwithstanding\", \"provided that\", \n",
    "            \"subject to\", \"pursuant to\", \"without prejudice\", \"hereinafter\"\n",
    "        ]\n",
    "        \n",
    "        # Count legal clauses (simple approach without spaCy)\n",
    "        query_lower = query.lower()\n",
    "        clause_count = sum(1 for marker in clause_markers if marker in query_lower)\n",
    "        \n",
    "        # Check for complex legal conditionals\n",
    "        has_conditionals = any(marker in query_lower for marker in clause_markers)\n",
    "        \n",
    "        # Basic syntactic complexity metrics without dependency parsing\n",
    "        sentences = self._split_into_sentences(query)\n",
    "        num_sentences = len(sentences)\n",
    "        \n",
    "        # Calculate average sentence length\n",
    "        total_words = sum(len(sentence.split()) for sentence in sentences)\n",
    "        avg_sent_length = total_words / num_sentences if num_sentences > 0 else 0\n",
    "        \n",
    "        # Normalize sentence length complexity\n",
    "        sent_complexity = min(1.0, avg_sent_length / 35)\n",
    "        \n",
    "        # Estimate complexity based on punctuation density\n",
    "        punctuation_count = sum(1 for char in query if char in \",.;:()[]{}\") \n",
    "        punct_density = punctuation_count / len(query) if len(query) > 0 else 0\n",
    "        punct_complexity = min(1.0, punct_density * 10)\n",
    "        \n",
    "        # Calculate overall complexity\n",
    "        complexity = min(1.0, \n",
    "                        (clause_count * 0.15) + \n",
    "                        (0.25 if has_conditionals else 0) + \n",
    "                        (sent_complexity * 0.3) +\n",
    "                        (punct_complexity * 0.3))\n",
    "        \n",
    "        return complexity\n",
    "    \n",
    "    def _split_into_sentences(self, text):\n",
    "        \"\"\"Split text into sentences without using spaCy.\"\"\"\n",
    "        # Simple sentence splitting using regex\n",
    "        # This is not as accurate as spaCy but works for basic cases\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        return [s for s in sentences if s]\n",
    "    \n",
    "    def _detect_jurisdiction(self, query):\n",
    "        \"\"\"\n",
    "        Detect jurisdictional signals in the query using regex patterns.\n",
    "        \n",
    "        Args:\n",
    "            query: The input query string\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of jurisdictional features with fuzzy scores\n",
    "        \"\"\"\n",
    "        # Initialize jurisdictions with fuzzy scores\n",
    "        jurisdictions = {\n",
    "            'federal': 0.0,\n",
    "            'state': 0.0,\n",
    "            'international': 0.0,\n",
    "            'specific_court': None,\n",
    "            'jurisdiction_score': 0.0  # Overall score\n",
    "        }\n",
    "        \n",
    "        # Federal jurisdiction signals\n",
    "        federal_terms = [\n",
    "            \"federal\", \"U.S.\", \"United States\", \"SCOTUS\", \"Supreme Court\", \n",
    "            \"U.S.C.\", \"Federal Circuit\", \"Fed. Cir.\", \"federal law\"\n",
    "        ]\n",
    "        \n",
    "        # Check for federal signals\n",
    "        query_lower = query.lower()\n",
    "        federal_score = 0.0\n",
    "        for term in federal_terms:\n",
    "            if term.lower() in query_lower:\n",
    "                federal_score = 1.0\n",
    "                break\n",
    "                \n",
    "            # Check for fuzzy matches\n",
    "            words = query_lower.split()\n",
    "            for word in words:\n",
    "                if self._string_similarity(term.lower(), word) > 0.85:\n",
    "                    federal_score = max(federal_score, 0.7)\n",
    "        \n",
    "        jurisdictions['federal'] = federal_score\n",
    "        \n",
    "        # State jurisdiction signals\n",
    "        state_names = [\n",
    "            \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \n",
    "            \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \n",
    "            \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \n",
    "            \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \n",
    "            \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \n",
    "            \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \n",
    "            \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \n",
    "            \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \n",
    "            \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \n",
    "            \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "        ]\n",
    "        \n",
    "        # Check for state signals\n",
    "        state_score = 0.0\n",
    "        for state in state_names:\n",
    "            if state in query:\n",
    "                state_score = 1.0\n",
    "                break\n",
    "        \n",
    "        # Check for state abbreviations\n",
    "        if state_score < 1.0:\n",
    "            state_abbr_pattern = r'\\b([A-Z]{2})\\b'\n",
    "            potential_abbrs = re.findall(state_abbr_pattern, query)\n",
    "            state_abbrs = [\n",
    "                \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "                \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "                \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "                \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "                \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "            ]\n",
    "            for abbr in potential_abbrs:\n",
    "                if abbr in state_abbrs:\n",
    "                    state_score = 1.0\n",
    "                    break\n",
    "        \n",
    "        jurisdictions['state'] = state_score\n",
    "        \n",
    "        # International jurisdiction signals\n",
    "        international_terms = [\n",
    "            \"international\", \"foreign\", \"treaty\", \"convention\", \"protocol\",\n",
    "            \"transnational\", \"global\", \"worldwide\", \"UN\", \"United Nations\"\n",
    "        ]\n",
    "        \n",
    "        # Check for international signals\n",
    "        international_score = 0.0\n",
    "        for term in international_terms:\n",
    "            if term.lower() in query_lower:\n",
    "                international_score = 1.0\n",
    "                break\n",
    "                \n",
    "            # Check for fuzzy matches\n",
    "            words = query_lower.split()\n",
    "            for word in words:\n",
    "                if self._string_similarity(term.lower(), word) > 0.85:\n",
    "                    international_score = max(international_score, 0.7)\n",
    "        \n",
    "        jurisdictions['international'] = international_score\n",
    "        \n",
    "        # Court-specific signals\n",
    "        court_patterns = [\n",
    "            \"Circuit\", \"District Court\", \"Supreme Court\", \"Court of Appeals\", \n",
    "            \"Bankruptcy Court\", \"Tax Court\", \"Court of Claims\"\n",
    "        ]\n",
    "        \n",
    "        # Check for specific court mentions\n",
    "        for pattern in court_patterns:\n",
    "            if pattern in query:\n",
    "                jurisdictions['specific_court'] = pattern\n",
    "                break\n",
    "        \n",
    "        # Calculate overall jurisdiction specificity score\n",
    "        jurisdictions['jurisdiction_score'] = max(\n",
    "            federal_score,\n",
    "            state_score,\n",
    "            international_score,\n",
    "            1.0 if jurisdictions['specific_court'] else 0.0\n",
    "        )\n",
    "        \n",
    "        return jurisdictions\n",
    "    \n",
    "    def _fuzzify_features(self, features):\n",
    "        \"\"\"\n",
    "        Calculate fuzzy membership values for each feature.\n",
    "        \n",
    "        Args:\n",
    "            features: Dictionary of extracted feature values\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of fuzzy membership values\n",
    "        \"\"\"\n",
    "        memberships = {}\n",
    "        \n",
    "        # Fuzzify legal term density\n",
    "        memberships['legal_term_density'] = {\n",
    "            'low': self._trapezoid_membership(\n",
    "                features['legal_term_density'],\n",
    "                **self.fuzzy_sets['legal_term_density']['low']\n",
    "            ),\n",
    "            'medium': self._triangle_membership(\n",
    "                features['legal_term_density'],\n",
    "                **self.fuzzy_sets['legal_term_density']['medium']\n",
    "            ),\n",
    "            'high': self._trapezoid_membership(\n",
    "                features['legal_term_density'],\n",
    "                **self.fuzzy_sets['legal_term_density']['high']\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Fuzzify citation count\n",
    "        memberships['citation_count'] = {\n",
    "            'none': self._triangle_membership(\n",
    "                features['citation_count'],\n",
    "                **self.fuzzy_sets['citation_count']['none']\n",
    "            ),\n",
    "            'few': self._triangle_membership(\n",
    "                features['citation_count'],\n",
    "                **self.fuzzy_sets['citation_count']['few']\n",
    "            ),\n",
    "            'many': self._trapezoid_membership(\n",
    "                features['citation_count'],\n",
    "                **self.fuzzy_sets['citation_count']['many']\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Fuzzify structural complexity\n",
    "        memberships['structural_complexity'] = {\n",
    "            'simple': self._trapezoid_membership(\n",
    "                features['structural_complexity'],\n",
    "                **self.fuzzy_sets['structural_complexity']['simple']\n",
    "            ),\n",
    "            'moderate': self._triangle_membership(\n",
    "                features['structural_complexity'],\n",
    "                **self.fuzzy_sets['structural_complexity']['moderate']\n",
    "            ),\n",
    "            'complex': self._trapezoid_membership(\n",
    "                features['structural_complexity'],\n",
    "                **self.fuzzy_sets['structural_complexity']['complex']\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Fuzzify jurisdiction score\n",
    "        memberships['jurisdiction_score'] = {\n",
    "            'general': self._trapezoid_membership(\n",
    "                features['jurisdiction_score'],\n",
    "                **self.fuzzy_sets['jurisdiction_score']['general']\n",
    "            ),\n",
    "            'specific': self._trapezoid_membership(\n",
    "                features['jurisdiction_score'],\n",
    "                **self.fuzzy_sets['jurisdiction_score']['specific']\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        return memberships\n",
    "    \n",
    "    def _trapezoid_membership(self, x, a, b, c, d):\n",
    "        \"\"\"\n",
    "        Trapezoidal membership function.\n",
    "        \n",
    "        Args:\n",
    "            x: Input value\n",
    "            a, b, c, d: Trapezoid parameters\n",
    "                0 for x <= a or x >= d\n",
    "                1 for b <= x <= c\n",
    "                Rising from a to b\n",
    "                Falling from c to d\n",
    "                \n",
    "        Returns:\n",
    "            Membership value between 0 and 1\n",
    "        \"\"\"\n",
    "        if x <= a or x >= d:\n",
    "            return 0\n",
    "        elif a < x < b:\n",
    "            return (x - a) / (b - a)\n",
    "        elif b <= x <= c:\n",
    "            return 1\n",
    "        else:  # c < x < d\n",
    "            return (d - x) / (d - c)\n",
    "    \n",
    "    def _triangle_membership(self, x, a, b, c):\n",
    "        \"\"\"\n",
    "        Triangular membership function.\n",
    "        \n",
    "        Args:\n",
    "            x: Input value\n",
    "            a, b, c: Triangle parameters\n",
    "                0 for x <= a or x >= c\n",
    "                1 for x = b\n",
    "                Rising from a to b\n",
    "                Falling from b to c\n",
    "                \n",
    "        Returns:\n",
    "            Membership value between 0 and 1\n",
    "        \"\"\"\n",
    "        if x <= a or x >= c:\n",
    "            return 0\n",
    "        elif a < x <= b:\n",
    "            return (x - a) / (b - a)\n",
    "        else:  # b < x < c\n",
    "            return (c - x) / (c - b)\n",
    "    \n",
    "    def _fuzzy_inference(self, fuzzy_memberships):\n",
    "        \"\"\"\n",
    "        Apply fuzzy inference rules with amplification to determine model weights.\n",
    "        \"\"\"\n",
    "        rule_activations = []\n",
    "        \n",
    "        # Apply each rule\n",
    "        for rule in self.fuzzy_rules:\n",
    "            # Calculate rule strength (using min as T-norm for AND operation)\n",
    "            strengths = []\n",
    "            for feature, category in rule['conditions'].items():\n",
    "                if feature in fuzzy_memberships and category in fuzzy_memberships[feature]:\n",
    "                    strengths.append(fuzzy_memberships[feature][category])\n",
    "            \n",
    "            # Apply AND operation across all conditions (min)\n",
    "            if strengths:\n",
    "                rule_strength = min(strengths)\n",
    "                rule_activations.append((rule_strength, rule['weight']))\n",
    "        \n",
    "        # If no rules activate strongly, default to mid-range weight\n",
    "        if not rule_activations or max(strength for strength, _ in rule_activations) < 0.1:\n",
    "            voyager_weight = 0.6  # Default weight\n",
    "        else:\n",
    "            # Amplify strongest rule activations\n",
    "            # Square the strengths to give more weight to stronger matches\n",
    "            numerator = sum((strength ** 2) * weight for strength, weight in rule_activations)\n",
    "            denominator = sum((strength ** 2) for strength, _ in rule_activations)\n",
    "            \n",
    "            if denominator > 0:\n",
    "                voyager_weight = numerator / denominator\n",
    "            else:\n",
    "                voyager_weight = 0.6  # Default weight\n",
    "\n",
    "        if voyager_weight > 0.6:\n",
    "            # Amplify high weights (legal queries)\n",
    "            voyager_weight = 0.6 + (voyager_weight - 0.6) * 1.5\n",
    "        elif voyager_weight < 0.6:\n",
    "            # Amplify low weights (standard queries)\n",
    "            voyager_weight = 0.6 - (0.6 - voyager_weight) * 1.5\n",
    "        \n",
    "        # Ensure weights are within valid range\n",
    "        voyager_weight = min(max(voyager_weight, 0.1), 0.95)\n",
    "        gemini_weight = 1.0 - voyager_weight\n",
    "        \n",
    "        return {\n",
    "            'gemini': gemini_weight,\n",
    "            'voyager': voyager_weight\n",
    "        }\n",
    "\n",
    "    \n",
    "\n",
    "analyzer = LegalQueryAnalyzer(use_gemini=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY 1: Pursuant to 18 U.S.C. § 203(c)(1) and (d)(1), what defenses might be available to a special Government employee who received $2,000 compensation for representational services before the Department of Energy regarding Contract No. DE-AC01-23XYZ45678, where said employee had previously rendered technical advice on the same matter during their 45-day appointment, and would the exemption in subsection (e) requiring Federal Register publication apply notwithstanding the 'personal and substantial participation' prohibition?\n",
      "================================================================================\n",
      "\n",
      "FEATURES:\n",
      "  legal_term_density: 1.4492753623188406\n",
      "  citation_count: 0.5\n",
      "  structural_complexity: 0.8503933351543295\n",
      "  query_length: 106\n",
      "  jurisdiction_score: 1.0\n",
      "  jurisdiction_score: 1.0\n",
      "\n",
      "FUZZY MEMBERSHIPS:\n",
      "  legal_term_density:\n",
      "    low: 0.55\n",
      "    medium: 0.22\n",
      "    high: 0.00\n",
      "  citation_count:\n",
      "    none: 0.00\n",
      "    few: 1.00\n",
      "    many: 0.00\n",
      "  structural_complexity:\n",
      "    simple: 0.00\n",
      "    moderate: 0.00\n",
      "    complex: 1.00\n",
      "  jurisdiction_score:\n",
      "    general: 0.00\n",
      "    specific: 0.00\n",
      "\n",
      "MODEL WEIGHTS:\n",
      "  Gemini: 0.50\n",
      "  Voyager: 0.50\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY 2: Does the statutory prohibition in 18 U.S.C. § 203(a)(1)(B) against federal employees receiving compensation for representational services extend to matters where the United States is not a named party but merely has a 'direct and substantial interest' in a proceeding before a military commission?\n",
      "================================================================================\n",
      "\n",
      "FEATURES:\n",
      "  legal_term_density: 2.272727272727273\n",
      "  citation_count: 0\n",
      "  structural_complexity: 0.27948051948051944\n",
      "  query_length: 59\n",
      "  jurisdiction_score: 1.0\n",
      "  jurisdiction_score: 1.0\n",
      "\n",
      "FUZZY MEMBERSHIPS:\n",
      "  legal_term_density:\n",
      "    low: 0.00\n",
      "    medium: 0.64\n",
      "    high: 0.00\n",
      "  citation_count:\n",
      "    none: 0.00\n",
      "    few: 0.00\n",
      "    many: 0.00\n",
      "  structural_complexity:\n",
      "    simple: 0.21\n",
      "    moderate: 0.40\n",
      "    complex: 0.00\n",
      "  jurisdiction_score:\n",
      "    general: 0.00\n",
      "    specific: 0.00\n",
      "\n",
      "MODEL WEIGHTS:\n",
      "  Gemini: 0.37\n",
      "  Voyager: 0.63\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY 3: As a federal employee, would I violate conflict of interest laws if I represent my brother's company in their application for a government grant, even if I work in a completely different agency than the one reviewing the application?\n",
      "================================================================================\n",
      "\n",
      "FEATURES:\n",
      "  legal_term_density: 0.0\n",
      "  citation_count: 0\n",
      "  structural_complexity: 0.7257510729613733\n",
      "  query_length: 43\n",
      "  jurisdiction_score: 1.0\n",
      "  jurisdiction_score: 1.0\n",
      "\n",
      "FUZZY MEMBERSHIPS:\n",
      "  legal_term_density:\n",
      "    low: 0.00\n",
      "    medium: 0.00\n",
      "    high: 0.00\n",
      "  citation_count:\n",
      "    none: 0.00\n",
      "    few: 0.00\n",
      "    many: 0.00\n",
      "  structural_complexity:\n",
      "    simple: 0.00\n",
      "    moderate: 0.00\n",
      "    complex: 1.00\n",
      "  jurisdiction_score:\n",
      "    general: 0.00\n",
      "    specific: 0.00\n",
      "\n",
      "MODEL WEIGHTS:\n",
      "  Gemini: 0.40\n",
      "  Voyager: 0.60\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY 4: I work for the city government and my sister needs help with her tax problem. Can I write a letter to the IRS for her if she pays me a small fee for my time?\n",
      "================================================================================\n",
      "\n",
      "FEATURES:\n",
      "  legal_term_density: 2.857142857142857\n",
      "  citation_count: 0\n",
      "  structural_complexity: 0.5691082802547771\n",
      "  query_length: 37\n",
      "  jurisdiction_score: 0.0\n",
      "  jurisdiction_score: 0.0\n",
      "\n",
      "FUZZY MEMBERSHIPS:\n",
      "  legal_term_density:\n",
      "    low: 0.00\n",
      "    medium: 0.93\n",
      "    high: 0.00\n",
      "  citation_count:\n",
      "    none: 0.00\n",
      "    few: 0.00\n",
      "    many: 0.00\n",
      "  structural_complexity:\n",
      "    simple: 0.00\n",
      "    moderate: 0.15\n",
      "    complex: 0.35\n",
      "  jurisdiction_score:\n",
      "    general: 0.00\n",
      "    specific: 0.00\n",
      "\n",
      "MODEL WEIGHTS:\n",
      "  Gemini: 0.37\n",
      "  Voyager: 0.63\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY 5: My friend who works for the government helped me fill out some paperwork last weekend. I bought him dinner as a thank you. Is that going to get him in trouble?\n",
      "================================================================================\n",
      "\n",
      "FEATURES:\n",
      "  legal_term_density: 0.0\n",
      "  citation_count: 0\n",
      "  structural_complexity: 0.12630727762803234\n",
      "  query_length: 34\n",
      "  jurisdiction_score: 0.0\n",
      "  jurisdiction_score: 0.0\n",
      "\n",
      "FUZZY MEMBERSHIPS:\n",
      "  legal_term_density:\n",
      "    low: 0.00\n",
      "    medium: 0.00\n",
      "    high: 0.00\n",
      "  citation_count:\n",
      "    none: 0.00\n",
      "    few: 0.00\n",
      "    many: 0.00\n",
      "  structural_complexity:\n",
      "    simple: 1.00\n",
      "    moderate: 0.00\n",
      "    complex: 0.00\n",
      "  jurisdiction_score:\n",
      "    general: 0.00\n",
      "    specific: 0.00\n",
      "\n",
      "MODEL WEIGHTS:\n",
      "  Gemini: 0.40\n",
      "  Voyager: 0.60\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF MODEL WEIGHTS\n",
      "================================================================================\n",
      "\n",
      "Query Type      Gemini     Voyager   \n",
      "------------------------------------\n",
      "Very Legal      0.50       0.50      \n",
      "Moderately Legal 0.37       0.63      \n",
      "Somewhat Legal  0.40       0.60      \n",
      "Minimally Legal 0.37       0.63      \n",
      "Standard        0.40       0.60      \n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    # Extremely Legal Query (highly technical, multiple citations, complex structure)\n",
    "    \"Pursuant to 18 U.S.C. § 203(c)(1) and (d)(1), what defenses might be available to a special Government employee who received $2,000 compensation for representational services before the Department of Energy regarding Contract No. DE-AC01-23XYZ45678, where said employee had previously rendered technical advice on the same matter during their 45-day appointment, and would the exemption in subsection (e) requiring Federal Register publication apply notwithstanding the 'personal and substantial participation' prohibition?\",\n",
    "    \n",
    "    # Very Legal Query (formal legal terminology, one citation, moderate complexity)\n",
    "    \"Does the statutory prohibition in 18 U.S.C. § 203(a)(1)(B) against federal employees receiving compensation for representational services extend to matters where the United States is not a named party but merely has a 'direct and substantial interest' in a proceeding before a military commission?\",\n",
    "    \n",
    "    # Moderately Legal Query (some legal terms, no citations, straightforward structure)\n",
    "    \"As a federal employee, would I violate conflict of interest laws if I represent my brother's company in their application for a government grant, even if I work in a completely different agency than the one reviewing the application?\",\n",
    "    \n",
    "    # Slightly Legal Query (minimal legal terminology, everyday language)\n",
    "    \"I work for the city government and my sister needs help with her tax problem. Can I write a letter to the IRS for her if she pays me a small fee for my time?\",\n",
    "    \n",
    "    # Standard Query (completely conversational, no legal terminology)\n",
    "    \"My friend who works for the government helped me fill out some paperwork last weekend. I bought him dinner as a thank you. Is that going to get him in trouble?\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def test_legal_query_analyzer(analyzer):\n",
    "    \"\"\"Test the LegalQueryAnalyzer with a range of queries from very legal to standard.\"\"\"\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for i, query in enumerate(test_queries):\n",
    "        print(f\"\\n\\n{'='*80}\")\n",
    "        print(f\"QUERY {i+1}: {query}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Analyze the query\n",
    "        result = analyzer.analyze_query(query)\n",
    "        \n",
    "        # Store results for comparison\n",
    "        results.append(result)\n",
    "        \n",
    "        # Print key metrics (excluding the embeddings which would be too verbose)\n",
    "        print(\"\\nFEATURES:\")\n",
    "        for feature, value in result['features'].items():\n",
    "            if feature != 'jurisdiction_signals':  # This would be too verbose\n",
    "                print(f\"  {feature}: {value}\")\n",
    "            elif feature == 'jurisdiction_signals':\n",
    "                print(f\"  jurisdiction_score: {result['features']['jurisdiction_signals']['jurisdiction_score']}\")\n",
    "        \n",
    "        print(\"\\nFUZZY MEMBERSHIPS:\")\n",
    "        for feature, memberships in result['fuzzy_memberships'].items():\n",
    "            print(f\"  {feature}:\")\n",
    "            for category, membership in memberships.items():\n",
    "                print(f\"    {category}: {membership:.2f}\")\n",
    "        \n",
    "        print(\"\\nMODEL WEIGHTS:\")\n",
    "        print(f\"  Gemini: {result['weights']['gemini']:.2f}\")\n",
    "        print(f\"  Voyager: {result['weights']['voyager']:.2f}\")\n",
    "    \n",
    "    # Compare weights across queries\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY OF MODEL WEIGHTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n{:<15} {:<10} {:<10}\".format(\"Query Type\", \"Gemini\", \"Voyager\"))\n",
    "    print(\"-\"*36)\n",
    "    \n",
    "    query_types = [\"Very Legal\", \"Moderately Legal\", \"Somewhat Legal\", \"Minimally Legal\", \"Standard\"]\n",
    "    \n",
    "    for i, query_type in enumerate(query_types):\n",
    "        gemini = results[i]['weights']['gemini']\n",
    "        voyager = results[i]['weights']['voyager']\n",
    "        print(\"{:<15} {:<10.2f} {:<10.2f}\".format(query_type, gemini, voyager))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_legal_query_analyzer(analyzer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athlyze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
